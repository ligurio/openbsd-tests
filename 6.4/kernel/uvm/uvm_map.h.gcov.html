<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - 6.4 - uvm/uvm_map.h</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">uvm</a> - uvm_map.h<span style="font-size: 80%;"> (source / <a href="uvm_map.h.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">6.4</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">1</td>
            <td class="headerCovTableEntry">1</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2018-10-19 03:25:38</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">14</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Legend:</td>
            <td class="headerValueLeg">            Lines:
            <span class="coverLegendCov">hit</span>
            <span class="coverLegendNoCov">not hit</span>
</td>
            <td></td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /*      $OpenBSD: uvm_map.h,v 1.60 2018/04/12 17:13:44 deraadt Exp $    */</a>
<span class="lineNum">       2 </span>            : /*      $NetBSD: uvm_map.h,v 1.24 2001/02/18 21:19:08 chs Exp $ */
<span class="lineNum">       3 </span>            : 
<span class="lineNum">       4 </span>            : /*
<span class="lineNum">       5 </span>            :  * Copyright (c) 2011 Ariane van der Steldt &lt;ariane@openbsd.org&gt;
<span class="lineNum">       6 </span>            :  *
<span class="lineNum">       7 </span>            :  * Permission to use, copy, modify, and distribute this software for any
<span class="lineNum">       8 </span>            :  * purpose with or without fee is hereby granted, provided that the above
<span class="lineNum">       9 </span>            :  * copyright notice and this permission notice appear in all copies.
<span class="lineNum">      10 </span>            :  *
<span class="lineNum">      11 </span>            :  * THE SOFTWARE IS PROVIDED &quot;AS IS&quot; AND THE AUTHOR DISCLAIMS ALL WARRANTIES
<span class="lineNum">      12 </span>            :  * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
<span class="lineNum">      13 </span>            :  * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
<span class="lineNum">      14 </span>            :  * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
<span class="lineNum">      15 </span>            :  * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
<span class="lineNum">      16 </span>            :  * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
<span class="lineNum">      17 </span>            :  * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
<span class="lineNum">      18 </span>            :  *
<span class="lineNum">      19 </span>            :  * 
<span class="lineNum">      20 </span>            :  * Copyright (c) 1997 Charles D. Cranor and Washington University.
<span class="lineNum">      21 </span>            :  * Copyright (c) 1991, 1993, The Regents of the University of California.  
<span class="lineNum">      22 </span>            :  *
<span class="lineNum">      23 </span>            :  * All rights reserved.
<span class="lineNum">      24 </span>            :  *
<span class="lineNum">      25 </span>            :  * This code is derived from software contributed to Berkeley by
<span class="lineNum">      26 </span>            :  * The Mach Operating System project at Carnegie-Mellon University.
<span class="lineNum">      27 </span>            :  *
<span class="lineNum">      28 </span>            :  * Redistribution and use in source and binary forms, with or without
<span class="lineNum">      29 </span>            :  * modification, are permitted provided that the following conditions
<span class="lineNum">      30 </span>            :  * are met:
<span class="lineNum">      31 </span>            :  * 1. Redistributions of source code must retain the above copyright
<span class="lineNum">      32 </span>            :  *    notice, this list of conditions and the following disclaimer.
<span class="lineNum">      33 </span>            :  * 2. Redistributions in binary form must reproduce the above copyright
<span class="lineNum">      34 </span>            :  *    notice, this list of conditions and the following disclaimer in the
<span class="lineNum">      35 </span>            :  *    documentation and/or other materials provided with the distribution.
<span class="lineNum">      36 </span>            :  * 3. Neither the name of the University nor the names of its contributors
<span class="lineNum">      37 </span>            :  *    may be used to endorse or promote products derived from this software
<span class="lineNum">      38 </span>            :  *    without specific prior written permission.
<span class="lineNum">      39 </span>            :  *
<span class="lineNum">      40 </span>            :  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
<span class="lineNum">      41 </span>            :  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
<span class="lineNum">      42 </span>            :  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
<span class="lineNum">      43 </span>            :  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
<span class="lineNum">      44 </span>            :  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
<span class="lineNum">      45 </span>            :  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
<span class="lineNum">      46 </span>            :  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
<span class="lineNum">      47 </span>            :  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
<span class="lineNum">      48 </span>            :  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
<span class="lineNum">      49 </span>            :  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
<span class="lineNum">      50 </span>            :  * SUCH DAMAGE.
<span class="lineNum">      51 </span>            :  *
<span class="lineNum">      52 </span>            :  *      @(#)vm_map.h    8.3 (Berkeley) 3/15/94
<span class="lineNum">      53 </span>            :  * from: Id: uvm_map.h,v 1.1.2.3 1998/02/07 01:16:55 chs Exp
<span class="lineNum">      54 </span>            :  *
<span class="lineNum">      55 </span>            :  *
<span class="lineNum">      56 </span>            :  * Copyright (c) 1987, 1990 Carnegie-Mellon University.
<span class="lineNum">      57 </span>            :  * All rights reserved.
<span class="lineNum">      58 </span>            :  * 
<span class="lineNum">      59 </span>            :  * Permission to use, copy, modify and distribute this software and
<span class="lineNum">      60 </span>            :  * its documentation is hereby granted, provided that both the copyright
<span class="lineNum">      61 </span>            :  * notice and this permission notice appear in all copies of the
<span class="lineNum">      62 </span>            :  * software, derivative works or modified versions, and any portions
<span class="lineNum">      63 </span>            :  * thereof, and that both notices appear in supporting documentation.
<span class="lineNum">      64 </span>            :  * 
<span class="lineNum">      65 </span>            :  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS &quot;AS IS&quot; 
<span class="lineNum">      66 </span>            :  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND 
<span class="lineNum">      67 </span>            :  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
<span class="lineNum">      68 </span>            :  * 
<span class="lineNum">      69 </span>            :  * Carnegie Mellon requests users of this software to return to
<span class="lineNum">      70 </span>            :  *
<span class="lineNum">      71 </span>            :  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU
<span class="lineNum">      72 </span>            :  *  School of Computer Science
<span class="lineNum">      73 </span>            :  *  Carnegie Mellon University
<span class="lineNum">      74 </span>            :  *  Pittsburgh PA 15213-3890
<span class="lineNum">      75 </span>            :  *
<span class="lineNum">      76 </span>            :  * any improvements or extensions that they make and grant Carnegie the
<span class="lineNum">      77 </span>            :  * rights to redistribute these changes.
<span class="lineNum">      78 </span>            :  */
<span class="lineNum">      79 </span>            : 
<span class="lineNum">      80 </span>            : #ifndef _UVM_UVM_MAP_H_
<span class="lineNum">      81 </span>            : #define _UVM_UVM_MAP_H_
<span class="lineNum">      82 </span>            : 
<span class="lineNum">      83 </span>            : #include &lt;sys/mutex.h&gt;
<span class="lineNum">      84 </span>            : #include &lt;sys/rwlock.h&gt;
<span class="lineNum">      85 </span>            : 
<span class="lineNum">      86 </span>            : #ifdef _KERNEL
<span class="lineNum">      87 </span>            : 
<span class="lineNum">      88 </span>            : /*
<span class="lineNum">      89 </span>            :  * Internal functions.
<span class="lineNum">      90 </span>            :  *
<span class="lineNum">      91 </span>            :  * Required by clipping macros.
<span class="lineNum">      92 </span>            :  */
<span class="lineNum">      93 </span>            : void                     uvm_map_clip_end(struct vm_map*, struct vm_map_entry*,
<span class="lineNum">      94 </span>            :                             vaddr_t);
<span class="lineNum">      95 </span>            : void                     uvm_map_clip_start(struct vm_map*,
<span class="lineNum">      96 </span>            :                             struct vm_map_entry*, vaddr_t);
<span class="lineNum">      97 </span>            : 
<span class="lineNum">      98 </span>            : /*
<span class="lineNum">      99 </span>            :  * UVM_MAP_CLIP_START: ensure that the entry begins at or after
<span class="lineNum">     100 </span>            :  * the starting address, if it doesn't we split the entry.
<span class="lineNum">     101 </span>            :  * 
<span class="lineNum">     102 </span>            :  * =&gt; map must be locked by caller
<span class="lineNum">     103 </span>            :  */
<span class="lineNum">     104 </span>            : 
<span class="lineNum">     105 </span>            : #define UVM_MAP_CLIP_START(_map, _entry, _addr)                         \
<span class="lineNum">     106 </span>            :         do {                                                            \
<span class="lineNum">     107 </span>            :                 KASSERT((_entry)-&gt;end + (_entry)-&gt;fspace &gt; (_addr));   \
<span class="lineNum">     108 </span>            :                 if ((_entry)-&gt;start &lt; (_addr))                            \
<span class="lineNum">     109 </span>            :                         uvm_map_clip_start((_map), (_entry), (_addr));  \
<span class="lineNum">     110 </span>            :         } while (0)
<span class="lineNum">     111 </span>            : 
<span class="lineNum">     112 </span>            : /*
<span class="lineNum">     113 </span>            :  * UVM_MAP_CLIP_END: ensure that the entry ends at or before
<span class="lineNum">     114 </span>            :  *      the ending address, if it does't we split the entry.
<span class="lineNum">     115 </span>            :  *
<span class="lineNum">     116 </span>            :  * =&gt; map must be locked by caller
<span class="lineNum">     117 </span>            :  */
<span class="lineNum">     118 </span>            : 
<span class="lineNum">     119 </span>            : #define UVM_MAP_CLIP_END(_map, _entry, _addr)                           \
<span class="lineNum">     120 </span>            :         do {                                                            \
<span class="lineNum">     121 </span>            :                 KASSERT((_entry)-&gt;start &lt; (_addr));                       \
<span class="lineNum">     122 </span>            :                 if ((_entry)-&gt;end &gt; (_addr))                              \
<span class="lineNum">     123 </span>            :                         uvm_map_clip_end((_map), (_entry), (_addr));    \
<span class="lineNum">     124 </span>            :         } while (0)
<span class="lineNum">     125 </span>            : 
<span class="lineNum">     126 </span>            : /*
<span class="lineNum">     127 </span>            :  * extract flags
<span class="lineNum">     128 </span>            :  */
<span class="lineNum">     129 </span>            : #define UVM_EXTRACT_FIXPROT     0x8     /* set prot to maxprot as we go */
<span class="lineNum">     130 </span>            : 
<span class="lineNum">     131 </span>            : #endif /* _KERNEL */
<span class="lineNum">     132 </span>            : 
<span class="lineNum">     133 </span>            : #include &lt;uvm/uvm_anon.h&gt;
<span class="lineNum">     134 </span>            : 
<span class="lineNum">     135 </span>            : /*
<span class="lineNum">     136 </span>            :  * types defined:
<span class="lineNum">     137 </span>            :  *
<span class="lineNum">     138 </span>            :  *      vm_map_t                the high-level address map data structure.
<span class="lineNum">     139 </span>            :  *      vm_map_entry_t          an entry in an address map.
<span class="lineNum">     140 </span>            :  *      vm_map_version_t        a timestamp of a map, for use with vm_map_lookup
<span class="lineNum">     141 </span>            :  */
<span class="lineNum">     142 </span>            : 
<span class="lineNum">     143 </span>            : /*
<span class="lineNum">     144 </span>            :  * Objects which live in maps may be either VM objects, or another map
<span class="lineNum">     145 </span>            :  * (called a &quot;sharing map&quot;) which denotes read-write sharing with other maps.
<span class="lineNum">     146 </span>            :  *
<span class="lineNum">     147 </span>            :  * XXXCDC: private pager data goes here now
<span class="lineNum">     148 </span>            :  */
<span class="lineNum">     149 </span>            : 
<span class="lineNum">     150 </span>            : union vm_map_object {
<span class="lineNum">     151 </span>            :         struct uvm_object       *uvm_obj;       /* UVM OBJECT */
<span class="lineNum">     152 </span>            :         struct vm_map           *sub_map;       /* belongs to another map */
<span class="lineNum">     153 </span>            : };
<span class="lineNum">     154 </span>            : 
<span class="lineNum">     155 </span>            : /*
<span class="lineNum">     156 </span>            :  * Address map entries consist of start and end addresses,
<span class="lineNum">     157 </span>            :  * a VM object (or sharing map) and offset into that object,
<span class="lineNum">     158 </span>            :  * and user-exported inheritance and protection information.
<span class="lineNum">     159 </span>            :  * Also included is control information for virtual copy operations.
<span class="lineNum">     160 </span>            :  */
<span class="lineNum">     161 </span>            : struct vm_map_entry {
<span class="lineNum">     162 </span>            :         union {
<span class="lineNum">     163 </span>            :                 RBT_ENTRY(vm_map_entry) addr_entry; /* address tree */
<span class="lineNum">     164 </span>            :                 SLIST_ENTRY(vm_map_entry) addr_kentry;
<span class="lineNum">     165 </span>            :         } daddrs;
<span class="lineNum">     166 </span>            : 
<span class="lineNum">     167 </span>            :         union {
<span class="lineNum">     168 </span>            :                 RBT_ENTRY(vm_map_entry) rbtree; /* Link freespace tree. */
<span class="lineNum">     169 </span>            :                 TAILQ_ENTRY(vm_map_entry) tailq;/* Link freespace queue. */
<span class="lineNum">     170 </span>            :                 TAILQ_ENTRY(vm_map_entry) deadq;/* dead entry queue */
<span class="lineNum">     171 </span>            :         } dfree;
<span class="lineNum">     172 </span>            : 
<span class="lineNum">     173 </span>            : #define uvm_map_entry_start_copy start
<span class="lineNum">     174 </span>            :         vaddr_t                 start;          /* start address */
<span class="lineNum">     175 </span>            :         vaddr_t                 end;            /* end address */
<span class="lineNum">     176 </span>            : 
<span class="lineNum">     177 </span>            :         vsize_t                 guard;          /* bytes in guard */
<span class="lineNum">     178 </span>            :         vsize_t                 fspace;         /* free space */
<span class="lineNum">     179 </span>            : 
<span class="lineNum">     180 </span>            :         union vm_map_object     object;         /* object I point to */
<span class="lineNum">     181 </span>            :         voff_t                  offset;         /* offset into object */
<span class="lineNum">     182 </span>            :         struct vm_aref          aref;           /* anonymous overlay */
<span class="lineNum">     183 </span>            : 
<span class="lineNum">     184 </span>            :         int                     etype;          /* entry type */
<span class="lineNum">     185 </span>            : 
<span class="lineNum">     186 </span>            :         vm_prot_t               protection;     /* protection code */
<span class="lineNum">     187 </span>            :         vm_prot_t               max_protection; /* maximum protection */
<span class="lineNum">     188 </span>            :         vm_inherit_t            inheritance;    /* inheritance */
<span class="lineNum">     189 </span>            : 
<span class="lineNum">     190 </span>            :         int                     wired_count;    /* can be paged if == 0 */
<span class="lineNum">     191 </span>            :         int                     advice;         /* madvise advice */
<span class="lineNum">     192 </span>            : #define uvm_map_entry_stop_copy flags
<span class="lineNum">     193 </span>            :         u_int8_t                flags;          /* flags */
<span class="lineNum">     194 </span>            : 
<span class="lineNum">     195 </span>            : #define UVM_MAP_STATIC          0x01            /* static map entry */
<span class="lineNum">     196 </span>            : #define UVM_MAP_KMEM            0x02            /* from kmem entry pool */
<span class="lineNum">     197 </span>            : 
<span class="lineNum">     198 </span>            :         vsize_t                 fspace_augment; /* max(fspace) in subtree */
<span class="lineNum">     199 </span>            : };
<span class="lineNum">     200 </span>            : 
<span class="lineNum">     201 </span>            : #define VM_MAPENT_ISWIRED(entry)        ((entry)-&gt;wired_count != 0)
<span class="lineNum">     202 </span>            : 
<span class="lineNum">     203 </span>            : TAILQ_HEAD(uvm_map_deadq, vm_map_entry);        /* dead entry queue */
<a name="204"><span class="lineNum">     204 </span>            : RBT_HEAD(uvm_map_addr, vm_map_entry);</a>
<span class="lineNum">     205 </span>            : #ifdef _KERNEL
<span class="lineNum">     206 </span><span class="lineCov">       1758 : RBT_PROTOTYPE(uvm_map_addr, vm_map_entry, daddrs.addr_entry,</span>
<span class="lineNum">     207 </span>            :     uvm_mapentry_addrcmp);
<span class="lineNum">     208 </span>            : #endif
<span class="lineNum">     209 </span>            : 
<span class="lineNum">     210 </span>            : /*
<span class="lineNum">     211 </span>            :  *      A Map is a rbtree of map entries, kept sorted by address.
<span class="lineNum">     212 </span>            :  *      In addition, free space entries are also kept in a rbtree,
<span class="lineNum">     213 </span>            :  *      indexed by free size.
<span class="lineNum">     214 </span>            :  *
<span class="lineNum">     215 </span>            :  *
<span class="lineNum">     216 </span>            :  *
<span class="lineNum">     217 </span>            :  *      LOCKING PROTOCOL NOTES:
<span class="lineNum">     218 </span>            :  *      -----------------------
<span class="lineNum">     219 </span>            :  *
<span class="lineNum">     220 </span>            :  *      VM map locking is a little complicated.  There are both shared
<span class="lineNum">     221 </span>            :  *      and exclusive locks on maps.  However, it is sometimes required
<span class="lineNum">     222 </span>            :  *      to downgrade an exclusive lock to a shared lock, and upgrade to
<span class="lineNum">     223 </span>            :  *      an exclusive lock again (to perform error recovery).  However,
<span class="lineNum">     224 </span>            :  *      another thread *must not* queue itself to receive an exclusive
<span class="lineNum">     225 </span>            :  *      lock while before we upgrade back to exclusive, otherwise the
<span class="lineNum">     226 </span>            :  *      error recovery becomes extremely difficult, if not impossible.
<span class="lineNum">     227 </span>            :  *
<span class="lineNum">     228 </span>            :  *      In order to prevent this scenario, we introduce the notion of
<span class="lineNum">     229 </span>            :  *      a `busy' map.  A `busy' map is read-locked, but other threads
<span class="lineNum">     230 </span>            :  *      attempting to write-lock wait for this flag to clear before
<span class="lineNum">     231 </span>            :  *      entering the lock manager.  A map may only be marked busy
<span class="lineNum">     232 </span>            :  *      when the map is write-locked (and then the map must be downgraded
<span class="lineNum">     233 </span>            :  *      to read-locked), and may only be marked unbusy by the thread
<span class="lineNum">     234 </span>            :  *      which marked it busy (holding *either* a read-lock or a
<span class="lineNum">     235 </span>            :  *      write-lock, the latter being gained by an upgrade).
<span class="lineNum">     236 </span>            :  *
<span class="lineNum">     237 </span>            :  *      Access to the map `flags' member is controlled by the `flags_lock'
<span class="lineNum">     238 </span>            :  *      simple lock.  Note that some flags are static (set once at map
<span class="lineNum">     239 </span>            :  *      creation time, and never changed), and thus require no locking
<span class="lineNum">     240 </span>            :  *      to check those flags.  All flags which are r/w must be set or
<span class="lineNum">     241 </span>            :  *      cleared while the `flags_lock' is asserted.  Additional locking
<span class="lineNum">     242 </span>            :  *      requirements are:
<span class="lineNum">     243 </span>            :  *
<span class="lineNum">     244 </span>            :  *              VM_MAP_PAGEABLE         r/o static flag; no locking required
<span class="lineNum">     245 </span>            :  *
<span class="lineNum">     246 </span>            :  *              VM_MAP_INTRSAFE         r/o static flag; no locking required
<span class="lineNum">     247 </span>            :  *
<span class="lineNum">     248 </span>            :  *              VM_MAP_WIREFUTURE       r/w; may only be set or cleared when
<span class="lineNum">     249 </span>            :  *                                      map is write-locked.  may be tested
<span class="lineNum">     250 </span>            :  *                                      without asserting `flags_lock'.
<span class="lineNum">     251 </span>            :  *
<span class="lineNum">     252 </span>            :  *              VM_MAP_BUSY             r/w; may only be set when map is
<span class="lineNum">     253 </span>            :  *                                      write-locked, may only be cleared by
<span class="lineNum">     254 </span>            :  *                                      thread which set it, map read-locked
<span class="lineNum">     255 </span>            :  *                                      or write-locked.  must be tested
<span class="lineNum">     256 </span>            :  *                                      while `flags_lock' is asserted.
<span class="lineNum">     257 </span>            :  *
<span class="lineNum">     258 </span>            :  *              VM_MAP_WANTLOCK         r/w; may only be set when the map
<span class="lineNum">     259 </span>            :  *                                      is busy, and thread is attempting
<span class="lineNum">     260 </span>            :  *                                      to write-lock.  must be tested
<span class="lineNum">     261 </span>            :  *                                      while `flags_lock' is asserted.
<span class="lineNum">     262 </span>            :  *
<span class="lineNum">     263 </span>            :  *              VM_MAP_GUARDPAGES       r/o; must be specified at map
<span class="lineNum">     264 </span>            :  *                                      initialization time.
<span class="lineNum">     265 </span>            :  *                                      If set, guards will appear between
<span class="lineNum">     266 </span>            :  *                                      automatic allocations.
<span class="lineNum">     267 </span>            :  *                                      No locking required.
<span class="lineNum">     268 </span>            :  *
<span class="lineNum">     269 </span>            :  *              VM_MAP_ISVMSPACE        r/o; set by uvmspace_alloc.
<span class="lineNum">     270 </span>            :  *                                      Signifies that this map is a vmspace.
<span class="lineNum">     271 </span>            :  *                                      (The implementation treats all maps
<span class="lineNum">     272 </span>            :  *                                      without this bit as kernel maps.)
<span class="lineNum">     273 </span>            :  *                                      No locking required.
<span class="lineNum">     274 </span>            :  *
<span class="lineNum">     275 </span>            :  *
<span class="lineNum">     276 </span>            :  * All automatic allocations (uvm_map without MAP_FIXED) will allocate
<span class="lineNum">     277 </span>            :  * from vm_map.free.
<span class="lineNum">     278 </span>            :  * If that allocation fails:
<span class="lineNum">     279 </span>            :  * - vmspace maps will spill over into vm_map.bfree,
<span class="lineNum">     280 </span>            :  * - all other maps will call uvm_map_kmem_grow() to increase the arena.
<span class="lineNum">     281 </span>            :  * 
<span class="lineNum">     282 </span>            :  * vmspace maps have their data, brk() and stack arenas automatically
<span class="lineNum">     283 </span>            :  * updated when uvm_map() is invoked without MAP_FIXED.
<span class="lineNum">     284 </span>            :  * The spill over arena (vm_map.bfree) will contain the space in the brk()
<span class="lineNum">     285 </span>            :  * and stack ranges.
<span class="lineNum">     286 </span>            :  * Kernel maps never have a bfree arena and this tree will always be empty.
<span class="lineNum">     287 </span>            :  *
<span class="lineNum">     288 </span>            :  *
<span class="lineNum">     289 </span>            :  * read_locks and write_locks are used in lock debugging code.
<span class="lineNum">     290 </span>            :  */
<span class="lineNum">     291 </span>            : struct vm_map {
<span class="lineNum">     292 </span>            :         struct pmap *           pmap;           /* Physical map */
<span class="lineNum">     293 </span>            :         struct rwlock           lock;           /* Lock for map data */
<span class="lineNum">     294 </span>            :         struct mutex            mtx;
<span class="lineNum">     295 </span>            :         u_int                   serial;         /* signals stack changes */
<span class="lineNum">     296 </span>            : 
<span class="lineNum">     297 </span>            :         struct uvm_map_addr     addr;           /* Entry tree, by addr */
<span class="lineNum">     298 </span>            : 
<span class="lineNum">     299 </span>            :         vsize_t                 size;           /* virtual size */
<span class="lineNum">     300 </span>            :         int                     ref_count;      /* Reference count */
<span class="lineNum">     301 </span>            :         int                     flags;          /* flags */
<span class="lineNum">     302 </span>            :         struct mutex            flags_lock;     /* flags lock */
<span class="lineNum">     303 </span>            :         unsigned int            timestamp;      /* Version number */
<span class="lineNum">     304 </span>            : 
<span class="lineNum">     305 </span>            :         vaddr_t                 min_offset;     /* First address in map. */
<span class="lineNum">     306 </span>            :         vaddr_t                 max_offset;     /* Last address in map. */
<span class="lineNum">     307 </span>            : 
<span class="lineNum">     308 </span>            :         /*
<span class="lineNum">     309 </span>            :          * Allocation overflow regions.
<span class="lineNum">     310 </span>            :          */
<span class="lineNum">     311 </span>            :         vaddr_t                 b_start;        /* Start for brk() alloc. */
<span class="lineNum">     312 </span>            :         vaddr_t                 b_end;          /* End for brk() alloc. */
<span class="lineNum">     313 </span>            :         vaddr_t                 s_start;        /* Start for stack alloc. */
<span class="lineNum">     314 </span>            :         vaddr_t                 s_end;          /* End for stack alloc. */
<span class="lineNum">     315 </span>            : 
<span class="lineNum">     316 </span>            :         /*
<span class="lineNum">     317 </span>            :          * Special address selectors.
<span class="lineNum">     318 </span>            :          *
<span class="lineNum">     319 </span>            :          * The uaddr_exe mapping is used if:
<span class="lineNum">     320 </span>            :          * - protX is selected
<span class="lineNum">     321 </span>            :          * - the pointer is not NULL
<span class="lineNum">     322 </span>            :          *
<span class="lineNum">     323 </span>            :          * If uaddr_exe is not used, the other mappings are checked in
<span class="lineNum">     324 </span>            :          * order of appearance.
<span class="lineNum">     325 </span>            :          * If a hint is given, the selection will only be used if the hint
<span class="lineNum">     326 </span>            :          * falls in the range described by the mapping.
<span class="lineNum">     327 </span>            :          *
<span class="lineNum">     328 </span>            :          * The states are pointers because:
<span class="lineNum">     329 </span>            :          * - they may not all be in use
<span class="lineNum">     330 </span>            :          * - the struct size for different schemes is variable
<span class="lineNum">     331 </span>            :          *
<span class="lineNum">     332 </span>            :          * The uaddr_brk_stack selector will select addresses that are in
<span class="lineNum">     333 </span>            :          * the brk/stack area of the map.
<span class="lineNum">     334 </span>            :          */
<span class="lineNum">     335 </span>            :         struct uvm_addr_state   *uaddr_exe;     /* Executable selector. */
<span class="lineNum">     336 </span>            :         struct uvm_addr_state   *uaddr_any[4];  /* More selectors. */
<span class="lineNum">     337 </span>            :         struct uvm_addr_state   *uaddr_brk_stack; /* Brk/stack selector. */
<span class="lineNum">     338 </span>            : };
<span class="lineNum">     339 </span>            : 
<span class="lineNum">     340 </span>            : /* vm_map flags */
<span class="lineNum">     341 </span>            : #define VM_MAP_PAGEABLE         0x01            /* ro: entries are pageable */
<span class="lineNum">     342 </span>            : #define VM_MAP_INTRSAFE         0x02            /* ro: interrupt safe map */
<span class="lineNum">     343 </span>            : #define VM_MAP_WIREFUTURE       0x04            /* rw: wire future mappings */
<span class="lineNum">     344 </span>            : #define VM_MAP_BUSY             0x08            /* rw: map is busy */
<span class="lineNum">     345 </span>            : #define VM_MAP_WANTLOCK         0x10            /* rw: want to write-lock */
<span class="lineNum">     346 </span>            : #define VM_MAP_GUARDPAGES       0x20            /* rw: add guard pgs to map */
<span class="lineNum">     347 </span>            : #define VM_MAP_ISVMSPACE        0x40            /* ro: map is a vmspace */
<span class="lineNum">     348 </span>            : 
<span class="lineNum">     349 </span>            : /* XXX: number of kernel maps and entries to statically allocate */
<span class="lineNum">     350 </span>            : 
<span class="lineNum">     351 </span>            : #if !defined(MAX_KMAPENT)
<span class="lineNum">     352 </span>            : #define MAX_KMAPENT     1024    /* Sufficient to make it to the scheduler. */
<span class="lineNum">     353 </span>            : #endif  /* !defined MAX_KMAPENT */
<span class="lineNum">     354 </span>            : 
<span class="lineNum">     355 </span>            : #ifdef _KERNEL
<span class="lineNum">     356 </span>            : #define vm_map_modflags(map, set, clear)                                \
<span class="lineNum">     357 </span>            : do {                                                                    \
<span class="lineNum">     358 </span>            :         mtx_enter(&amp;(map)-&gt;flags_lock);                                   \
<span class="lineNum">     359 </span>            :         (map)-&gt;flags = ((map)-&gt;flags | (set)) &amp; ~(clear);             \
<span class="lineNum">     360 </span>            :         mtx_leave(&amp;(map)-&gt;flags_lock);                                   \
<span class="lineNum">     361 </span>            : } while (0)
<span class="lineNum">     362 </span>            : #endif /* _KERNEL */
<span class="lineNum">     363 </span>            : 
<span class="lineNum">     364 </span>            : /*
<span class="lineNum">     365 </span>            :  *      Interrupt-safe maps must also be kept on a special list,
<span class="lineNum">     366 </span>            :  *      to assist uvm_fault() in avoiding locking problems.
<span class="lineNum">     367 </span>            :  */
<span class="lineNum">     368 </span>            : struct vm_map_intrsafe {
<span class="lineNum">     369 </span>            :         struct vm_map   vmi_map;
<span class="lineNum">     370 </span>            :         LIST_ENTRY(vm_map_intrsafe) vmi_list;
<span class="lineNum">     371 </span>            : };
<span class="lineNum">     372 </span>            : 
<span class="lineNum">     373 </span>            : /*
<span class="lineNum">     374 </span>            :  * globals:
<span class="lineNum">     375 </span>            :  */
<span class="lineNum">     376 </span>            : 
<span class="lineNum">     377 </span>            : #ifdef _KERNEL
<span class="lineNum">     378 </span>            : 
<span class="lineNum">     379 </span>            : extern vaddr_t  uvm_maxkaddr;
<span class="lineNum">     380 </span>            : 
<span class="lineNum">     381 </span>            : /*
<span class="lineNum">     382 </span>            :  * protos: the following prototypes define the interface to vm_map
<span class="lineNum">     383 </span>            :  */
<span class="lineNum">     384 </span>            : 
<span class="lineNum">     385 </span>            : void            uvm_map_deallocate(vm_map_t);
<span class="lineNum">     386 </span>            : 
<span class="lineNum">     387 </span>            : int             uvm_map_clean(vm_map_t, vaddr_t, vaddr_t, int);
<span class="lineNum">     388 </span>            : vm_map_t        uvm_map_create(pmap_t, vaddr_t, vaddr_t, int);
<span class="lineNum">     389 </span>            : int             uvm_map_extract(struct vm_map*, vaddr_t, vsize_t, vaddr_t*,
<span class="lineNum">     390 </span>            :                     int);
<span class="lineNum">     391 </span>            : vaddr_t         uvm_map_pie(vaddr_t);
<span class="lineNum">     392 </span>            : vaddr_t         uvm_map_hint(struct vmspace *, vm_prot_t, vaddr_t, vaddr_t);
<span class="lineNum">     393 </span>            : int             uvm_map_inherit(vm_map_t, vaddr_t, vaddr_t, vm_inherit_t);
<span class="lineNum">     394 </span>            : int             uvm_map_advice(vm_map_t, vaddr_t, vaddr_t, int);
<span class="lineNum">     395 </span>            : void            uvm_map_init(void);
<span class="lineNum">     396 </span>            : boolean_t       uvm_map_lookup_entry(vm_map_t, vaddr_t, vm_map_entry_t *);
<span class="lineNum">     397 </span>            : boolean_t       uvm_map_check_stack_range(struct proc *, vaddr_t sp);
<span class="lineNum">     398 </span>            : boolean_t       uvm_map_is_stack_remappable(vm_map_t, vaddr_t, vsize_t);
<span class="lineNum">     399 </span>            : int             uvm_map_remap_as_stack(struct proc *, vaddr_t, vsize_t);
<span class="lineNum">     400 </span>            : int             uvm_map_replace(vm_map_t, vaddr_t, vaddr_t,
<span class="lineNum">     401 </span>            :                     vm_map_entry_t, int);
<span class="lineNum">     402 </span>            : int             uvm_map_reserve(vm_map_t, vsize_t, vaddr_t, vsize_t,
<span class="lineNum">     403 </span>            :                     vaddr_t *);
<span class="lineNum">     404 </span>            : void            uvm_map_setup(vm_map_t, vaddr_t, vaddr_t, int);
<span class="lineNum">     405 </span>            : int             uvm_map_submap(vm_map_t, vaddr_t, vaddr_t, vm_map_t);
<span class="lineNum">     406 </span>            : void            uvm_unmap(vm_map_t, vaddr_t, vaddr_t);
<span class="lineNum">     407 </span>            : void            uvm_map_set_uaddr(struct vm_map*, struct uvm_addr_state**,
<span class="lineNum">     408 </span>            :                     struct uvm_addr_state*);
<span class="lineNum">     409 </span>            : int             uvm_map_mquery(struct vm_map*, vaddr_t*, vsize_t, voff_t, int);
<span class="lineNum">     410 </span>            : 
<span class="lineNum">     411 </span>            : void            uvm_unmap_detach(struct uvm_map_deadq*, int);
<span class="lineNum">     412 </span>            : void            uvm_unmap_remove(struct vm_map*, vaddr_t, vaddr_t,
<span class="lineNum">     413 </span>            :                     struct uvm_map_deadq*, boolean_t, boolean_t);
<span class="lineNum">     414 </span>            : 
<span class="lineNum">     415 </span>            : struct kinfo_vmentry;
<span class="lineNum">     416 </span>            : 
<span class="lineNum">     417 </span>            : int             uvm_map_fill_vmmap(struct vm_map *, struct kinfo_vmentry *,
<span class="lineNum">     418 </span>            :                     size_t *);
<span class="lineNum">     419 </span>            : 
<span class="lineNum">     420 </span>            : #endif /* _KERNEL */
<span class="lineNum">     421 </span>            : 
<span class="lineNum">     422 </span>            : /*
<span class="lineNum">     423 </span>            :  * VM map locking operations:
<span class="lineNum">     424 </span>            :  *
<span class="lineNum">     425 </span>            :  *      These operations perform locking on the data portion of the
<span class="lineNum">     426 </span>            :  *      map.
<span class="lineNum">     427 </span>            :  *
<span class="lineNum">     428 </span>            :  *      vm_map_lock_try: try to lock a map, failing if it is already locked.
<span class="lineNum">     429 </span>            :  *
<span class="lineNum">     430 </span>            :  *      vm_map_lock: acquire an exclusive (write) lock on a map.
<span class="lineNum">     431 </span>            :  *
<span class="lineNum">     432 </span>            :  *      vm_map_lock_read: acquire a shared (read) lock on a map.
<span class="lineNum">     433 </span>            :  *
<span class="lineNum">     434 </span>            :  *      vm_map_unlock: release an exclusive lock on a map.
<span class="lineNum">     435 </span>            :  *
<span class="lineNum">     436 </span>            :  *      vm_map_unlock_read: release a shared lock on a map.
<span class="lineNum">     437 </span>            :  *
<span class="lineNum">     438 </span>            :  *      vm_map_downgrade: downgrade an exclusive lock to a shared lock.
<span class="lineNum">     439 </span>            :  *
<span class="lineNum">     440 </span>            :  *      vm_map_upgrade: upgrade a shared lock to an exclusive lock.
<span class="lineNum">     441 </span>            :  *
<span class="lineNum">     442 </span>            :  *      vm_map_busy: mark a map as busy.
<span class="lineNum">     443 </span>            :  *
<span class="lineNum">     444 </span>            :  *      vm_map_unbusy: clear busy status on a map.
<span class="lineNum">     445 </span>            :  *
<span class="lineNum">     446 </span>            :  */
<span class="lineNum">     447 </span>            : 
<span class="lineNum">     448 </span>            : #ifdef _KERNEL
<span class="lineNum">     449 </span>            : /*
<span class="lineNum">     450 </span>            :  * XXX: clean up later
<span class="lineNum">     451 </span>            :  * Half the kernel seems to depend on them being included here.
<span class="lineNum">     452 </span>            :  */
<span class="lineNum">     453 </span>            : #include &lt;sys/time.h&gt;
<span class="lineNum">     454 </span>            : #include &lt;sys/systm.h&gt;  /* for panic() */
<span class="lineNum">     455 </span>            : 
<span class="lineNum">     456 </span>            : boolean_t       vm_map_lock_try_ln(struct vm_map*, char*, int);
<span class="lineNum">     457 </span>            : void            vm_map_lock_ln(struct vm_map*, char*, int);
<span class="lineNum">     458 </span>            : void            vm_map_lock_read_ln(struct vm_map*, char*, int);
<span class="lineNum">     459 </span>            : void            vm_map_unlock_ln(struct vm_map*, char*, int);
<span class="lineNum">     460 </span>            : void            vm_map_unlock_read_ln(struct vm_map*, char*, int);
<span class="lineNum">     461 </span>            : void            vm_map_downgrade_ln(struct vm_map*, char*, int);
<span class="lineNum">     462 </span>            : void            vm_map_upgrade_ln(struct vm_map*, char*, int);
<span class="lineNum">     463 </span>            : void            vm_map_busy_ln(struct vm_map*, char*, int);
<span class="lineNum">     464 </span>            : void            vm_map_unbusy_ln(struct vm_map*, char*, int);
<span class="lineNum">     465 </span>            : 
<span class="lineNum">     466 </span>            : #ifdef DIAGNOSTIC
<span class="lineNum">     467 </span>            : #define vm_map_lock_try(map)    vm_map_lock_try_ln(map, __FILE__, __LINE__)
<span class="lineNum">     468 </span>            : #define vm_map_lock(map)        vm_map_lock_ln(map, __FILE__, __LINE__)
<span class="lineNum">     469 </span>            : #define vm_map_lock_read(map)   vm_map_lock_read_ln(map, __FILE__, __LINE__)
<span class="lineNum">     470 </span>            : #define vm_map_unlock(map)      vm_map_unlock_ln(map, __FILE__, __LINE__)
<span class="lineNum">     471 </span>            : #define vm_map_unlock_read(map) vm_map_unlock_read_ln(map, __FILE__, __LINE__)
<span class="lineNum">     472 </span>            : #define vm_map_downgrade(map)   vm_map_downgrade_ln(map, __FILE__, __LINE__)
<span class="lineNum">     473 </span>            : #define vm_map_upgrade(map)     vm_map_upgrade_ln(map, __FILE__, __LINE__)
<span class="lineNum">     474 </span>            : #define vm_map_busy(map)        vm_map_busy_ln(map, __FILE__, __LINE__)
<span class="lineNum">     475 </span>            : #define vm_map_unbusy(map)      vm_map_unbusy_ln(map, __FILE__, __LINE__)
<span class="lineNum">     476 </span>            : #else
<span class="lineNum">     477 </span>            : #define vm_map_lock_try(map)    vm_map_lock_try_ln(map, NULL, 0)
<span class="lineNum">     478 </span>            : #define vm_map_lock(map)        vm_map_lock_ln(map, NULL, 0)
<span class="lineNum">     479 </span>            : #define vm_map_lock_read(map)   vm_map_lock_read_ln(map, NULL, 0)
<span class="lineNum">     480 </span>            : #define vm_map_unlock(map)      vm_map_unlock_ln(map, NULL, 0)
<span class="lineNum">     481 </span>            : #define vm_map_unlock_read(map) vm_map_unlock_read_ln(map, NULL, 0)
<span class="lineNum">     482 </span>            : #define vm_map_downgrade(map)   vm_map_downgrade_ln(map, NULL, 0)
<span class="lineNum">     483 </span>            : #define vm_map_upgrade(map)     vm_map_upgrade_ln(map, NULL, 0)
<span class="lineNum">     484 </span>            : #define vm_map_busy(map)        vm_map_busy_ln(map, NULL, 0)
<span class="lineNum">     485 </span>            : #define vm_map_unbusy(map)      vm_map_unbusy_ln(map, NULL, 0)
<span class="lineNum">     486 </span>            : #endif
<span class="lineNum">     487 </span>            : 
<span class="lineNum">     488 </span>            : #endif /* _KERNEL */
<span class="lineNum">     489 </span>            : 
<span class="lineNum">     490 </span>            : /*
<span class="lineNum">     491 </span>            :  *      Functions implemented as macros
<span class="lineNum">     492 </span>            :  */
<span class="lineNum">     493 </span>            : #define         vm_map_min(map)         ((map)-&gt;min_offset)
<span class="lineNum">     494 </span>            : #define         vm_map_max(map)         ((map)-&gt;max_offset)
<span class="lineNum">     495 </span>            : #define         vm_map_pmap(map)        ((map)-&gt;pmap)
<span class="lineNum">     496 </span>            : 
<span class="lineNum">     497 </span>            : #endif /* _UVM_UVM_MAP_H_ */
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
