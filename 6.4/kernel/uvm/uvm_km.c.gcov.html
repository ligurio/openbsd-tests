<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - 6.4 - uvm/uvm_km.c</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">uvm</a> - uvm_km.c<span style="font-size: 80%;"> (source / <a href="uvm_km.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">6.4</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">252</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2018-10-19 03:25:38</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">17</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Legend:</td>
            <td class="headerValueLeg">            Lines:
            <span class="coverLegendCov">hit</span>
            <span class="coverLegendNoCov">not hit</span>
</td>
            <td></td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /*      $OpenBSD: uvm_km.c,v 1.130 2017/05/11 06:55:47 dlg Exp $        */</a>
<span class="lineNum">       2 </span>            : /*      $NetBSD: uvm_km.c,v 1.42 2001/01/14 02:10:01 thorpej Exp $      */
<span class="lineNum">       3 </span>            : 
<span class="lineNum">       4 </span>            : /* 
<span class="lineNum">       5 </span>            :  * Copyright (c) 1997 Charles D. Cranor and Washington University.
<span class="lineNum">       6 </span>            :  * Copyright (c) 1991, 1993, The Regents of the University of California.  
<span class="lineNum">       7 </span>            :  *
<span class="lineNum">       8 </span>            :  * All rights reserved.
<span class="lineNum">       9 </span>            :  *
<span class="lineNum">      10 </span>            :  * This code is derived from software contributed to Berkeley by
<span class="lineNum">      11 </span>            :  * The Mach Operating System project at Carnegie-Mellon University.
<span class="lineNum">      12 </span>            :  *
<span class="lineNum">      13 </span>            :  * Redistribution and use in source and binary forms, with or without
<span class="lineNum">      14 </span>            :  * modification, are permitted provided that the following conditions
<span class="lineNum">      15 </span>            :  * are met:
<span class="lineNum">      16 </span>            :  * 1. Redistributions of source code must retain the above copyright
<span class="lineNum">      17 </span>            :  *    notice, this list of conditions and the following disclaimer.
<span class="lineNum">      18 </span>            :  * 2. Redistributions in binary form must reproduce the above copyright
<span class="lineNum">      19 </span>            :  *    notice, this list of conditions and the following disclaimer in the
<span class="lineNum">      20 </span>            :  *    documentation and/or other materials provided with the distribution.
<span class="lineNum">      21 </span>            :  * 3. Neither the name of the University nor the names of its contributors
<span class="lineNum">      22 </span>            :  *    may be used to endorse or promote products derived from this software
<span class="lineNum">      23 </span>            :  *    without specific prior written permission.
<span class="lineNum">      24 </span>            :  *
<span class="lineNum">      25 </span>            :  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
<span class="lineNum">      26 </span>            :  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
<span class="lineNum">      27 </span>            :  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
<span class="lineNum">      28 </span>            :  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
<span class="lineNum">      29 </span>            :  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
<span class="lineNum">      30 </span>            :  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
<span class="lineNum">      31 </span>            :  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
<span class="lineNum">      32 </span>            :  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
<span class="lineNum">      33 </span>            :  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
<span class="lineNum">      34 </span>            :  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
<span class="lineNum">      35 </span>            :  * SUCH DAMAGE.
<span class="lineNum">      36 </span>            :  *
<span class="lineNum">      37 </span>            :  *      @(#)vm_kern.c   8.3 (Berkeley) 1/12/94
<span class="lineNum">      38 </span>            :  * from: Id: uvm_km.c,v 1.1.2.14 1998/02/06 05:19:27 chs Exp
<span class="lineNum">      39 </span>            :  *
<span class="lineNum">      40 </span>            :  *
<span class="lineNum">      41 </span>            :  * Copyright (c) 1987, 1990 Carnegie-Mellon University.
<span class="lineNum">      42 </span>            :  * All rights reserved.
<span class="lineNum">      43 </span>            :  * 
<span class="lineNum">      44 </span>            :  * Permission to use, copy, modify and distribute this software and
<span class="lineNum">      45 </span>            :  * its documentation is hereby granted, provided that both the copyright
<span class="lineNum">      46 </span>            :  * notice and this permission notice appear in all copies of the
<span class="lineNum">      47 </span>            :  * software, derivative works or modified versions, and any portions
<span class="lineNum">      48 </span>            :  * thereof, and that both notices appear in supporting documentation.
<span class="lineNum">      49 </span>            :  * 
<span class="lineNum">      50 </span>            :  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS &quot;AS IS&quot; 
<span class="lineNum">      51 </span>            :  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND 
<span class="lineNum">      52 </span>            :  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
<span class="lineNum">      53 </span>            :  * 
<span class="lineNum">      54 </span>            :  * Carnegie Mellon requests users of this software to return to
<span class="lineNum">      55 </span>            :  *
<span class="lineNum">      56 </span>            :  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU
<span class="lineNum">      57 </span>            :  *  School of Computer Science
<span class="lineNum">      58 </span>            :  *  Carnegie Mellon University
<span class="lineNum">      59 </span>            :  *  Pittsburgh PA 15213-3890
<span class="lineNum">      60 </span>            :  *
<span class="lineNum">      61 </span>            :  * any improvements or extensions that they make and grant Carnegie the
<span class="lineNum">      62 </span>            :  * rights to redistribute these changes.
<span class="lineNum">      63 </span>            :  */
<span class="lineNum">      64 </span>            : 
<span class="lineNum">      65 </span>            : /*
<span class="lineNum">      66 </span>            :  * uvm_km.c: handle kernel memory allocation and management
<span class="lineNum">      67 </span>            :  */
<span class="lineNum">      68 </span>            : 
<span class="lineNum">      69 </span>            : /*
<span class="lineNum">      70 </span>            :  * overview of kernel memory management:
<span class="lineNum">      71 </span>            :  *
<span class="lineNum">      72 </span>            :  * the kernel virtual address space is mapped by &quot;kernel_map.&quot;   kernel_map
<span class="lineNum">      73 </span>            :  * starts at a machine-dependent address and is VM_KERNEL_SPACE_SIZE bytes
<span class="lineNum">      74 </span>            :  * large.
<span class="lineNum">      75 </span>            :  *
<span class="lineNum">      76 </span>            :  * the kernel_map has several &quot;submaps.&quot;   submaps can only appear in 
<span class="lineNum">      77 </span>            :  * the kernel_map (user processes can't use them).   submaps &quot;take over&quot;
<span class="lineNum">      78 </span>            :  * the management of a sub-range of the kernel's address space.  submaps
<span class="lineNum">      79 </span>            :  * are typically allocated at boot time and are never released.   kernel
<span class="lineNum">      80 </span>            :  * virtual address space that is mapped by a submap is locked by the 
<span class="lineNum">      81 </span>            :  * submap's lock -- not the kernel_map's lock.
<span class="lineNum">      82 </span>            :  *
<span class="lineNum">      83 </span>            :  * thus, the useful feature of submaps is that they allow us to break
<span class="lineNum">      84 </span>            :  * up the locking and protection of the kernel address space into smaller
<span class="lineNum">      85 </span>            :  * chunks.
<span class="lineNum">      86 </span>            :  *
<span class="lineNum">      87 </span>            :  * The VM system has several standard kernel submaps:
<span class="lineNum">      88 </span>            :  *   kmem_map: Contains only wired kernel memory for malloc(9).
<span class="lineNum">      89 </span>            :  *             Note: All access to this map must be protected by splvm as
<span class="lineNum">      90 </span>            :  *             calls to malloc(9) are allowed in interrupt handlers.
<span class="lineNum">      91 </span>            :  *   exec_map: Memory to hold arguments to system calls are allocated from
<span class="lineNum">      92 </span>            :  *             this map.
<span class="lineNum">      93 </span>            :  *             XXX: This is primeraly used to artificially limit the number
<span class="lineNum">      94 </span>            :  *             of concurrent processes doing an exec.
<span class="lineNum">      95 </span>            :  *   phys_map: Buffers for vmapbuf (physio) are allocated from this map.
<span class="lineNum">      96 </span>            :  *
<span class="lineNum">      97 </span>            :  * the kernel allocates its private memory out of special uvm_objects whose
<span class="lineNum">      98 </span>            :  * reference count is set to UVM_OBJ_KERN (thus indicating that the objects
<span class="lineNum">      99 </span>            :  * are &quot;special&quot; and never die).   all kernel objects should be thought of
<span class="lineNum">     100 </span>            :  * as large, fixed-sized, sparsely populated uvm_objects.   each kernel 
<span class="lineNum">     101 </span>            :  * object is equal to the size of kernel virtual address space (i.e.
<span class="lineNum">     102 </span>            :  * VM_KERNEL_SPACE_SIZE).
<span class="lineNum">     103 </span>            :  *
<span class="lineNum">     104 </span>            :  * most kernel private memory lives in kernel_object.   the only exception
<span class="lineNum">     105 </span>            :  * to this is for memory that belongs to submaps that must be protected
<span class="lineNum">     106 </span>            :  * by splvm(). each of these submaps manages their own pages.
<span class="lineNum">     107 </span>            :  *
<span class="lineNum">     108 </span>            :  * note that just because a kernel object spans the entire kernel virtual
<span class="lineNum">     109 </span>            :  * address space doesn't mean that it has to be mapped into the entire space.
<span class="lineNum">     110 </span>            :  * large chunks of a kernel object's space go unused either because 
<span class="lineNum">     111 </span>            :  * that area of kernel VM is unmapped, or there is some other type of 
<span class="lineNum">     112 </span>            :  * object mapped into that range (e.g. a vnode).    for submap's kernel
<span class="lineNum">     113 </span>            :  * objects, the only part of the object that can ever be populated is the
<span class="lineNum">     114 </span>            :  * offsets that are managed by the submap.
<span class="lineNum">     115 </span>            :  *
<span class="lineNum">     116 </span>            :  * note that the &quot;offset&quot; in a kernel object is always the kernel virtual
<span class="lineNum">     117 </span>            :  * address minus the vm_map_min(kernel_map).
<span class="lineNum">     118 </span>            :  * example:
<span class="lineNum">     119 </span>            :  *   suppose kernel_map starts at 0xf8000000 and the kernel does a
<span class="lineNum">     120 </span>            :  *   uvm_km_alloc(kernel_map, PAGE_SIZE) [allocate 1 wired down page in the
<span class="lineNum">     121 </span>            :  *   kernel map].    if uvm_km_alloc returns virtual address 0xf8235000,
<span class="lineNum">     122 </span>            :  *   then that means that the page at offset 0x235000 in kernel_object is
<span class="lineNum">     123 </span>            :  *   mapped at 0xf8235000.   
<span class="lineNum">     124 </span>            :  *
<span class="lineNum">     125 </span>            :  * kernel objects have one other special property: when the kernel virtual
<span class="lineNum">     126 </span>            :  * memory mapping them is unmapped, the backing memory in the object is
<span class="lineNum">     127 </span>            :  * freed right away.   this is done with the uvm_km_pgremove() function.
<span class="lineNum">     128 </span>            :  * this has to be done because there is no backing store for kernel pages
<span class="lineNum">     129 </span>            :  * and no need to save them after they are no longer referenced.
<span class="lineNum">     130 </span>            :  */
<span class="lineNum">     131 </span>            : 
<span class="lineNum">     132 </span>            : #include &lt;sys/param.h&gt;
<span class="lineNum">     133 </span>            : #include &lt;sys/systm.h&gt;
<span class="lineNum">     134 </span>            : #include &lt;sys/kthread.h&gt;
<span class="lineNum">     135 </span>            : #include &lt;uvm/uvm.h&gt;
<span class="lineNum">     136 </span>            : 
<span class="lineNum">     137 </span>            : /*
<span class="lineNum">     138 </span>            :  * global data structures
<span class="lineNum">     139 </span>            :  */
<span class="lineNum">     140 </span>            : 
<span class="lineNum">     141 </span>            : struct vm_map *kernel_map = NULL;
<span class="lineNum">     142 </span>            : 
<span class="lineNum">     143 </span>            : /* Unconstraint range. */
<span class="lineNum">     144 </span>            : struct uvm_constraint_range     no_constraint = { 0x0, (paddr_t)-1 };
<span class="lineNum">     145 </span>            : 
<span class="lineNum">     146 </span>            : /*
<span class="lineNum">     147 </span>            :  * local data structues
<span class="lineNum">     148 </span>            :  */
<span class="lineNum">     149 </span>            : static struct vm_map            kernel_map_store;
<span class="lineNum">     150 </span>            : 
<span class="lineNum">     151 </span>            : /*
<span class="lineNum">     152 </span>            :  * uvm_km_init: init kernel maps and objects to reflect reality (i.e.
<span class="lineNum">     153 </span>            :  * KVM already allocated for text, data, bss, and static data structures).
<span class="lineNum">     154 </span>            :  *
<span class="lineNum">     155 </span>            :  * =&gt; KVM is defined by [base.. base + VM_KERNEL_SPACE_SIZE].
<span class="lineNum">     156 </span>            :  *    we assume that [base -&gt; start] has already been allocated and that
<span class="lineNum">     157 </span>            :  *    &quot;end&quot; is the end of the kernel image span.
<a name="158"><span class="lineNum">     158 </span>            :  */</a>
<span class="lineNum">     159 </span>            : void
<span class="lineNum">     160 </span><span class="lineNoCov">          0 : uvm_km_init(vaddr_t base, vaddr_t start, vaddr_t end)</span>
<span class="lineNum">     161 </span>            : {
<span class="lineNum">     162 </span>            :         /* kernel_object: for pageable anonymous kernel memory */
<span class="lineNum">     163 </span><span class="lineNoCov">          0 :         uao_init();</span>
<span class="lineNum">     164 </span><span class="lineNoCov">          0 :         uvm.kernel_object = uao_create(VM_KERNEL_SPACE_SIZE, UAO_FLAG_KERNOBJ);</span>
<span class="lineNum">     165 </span>            : 
<span class="lineNum">     166 </span>            :         /*
<span class="lineNum">     167 </span>            :          * init the map and reserve already allocated kernel space 
<span class="lineNum">     168 </span>            :          * before installing.
<span class="lineNum">     169 </span>            :          */
<span class="lineNum">     170 </span>            : 
<span class="lineNum">     171 </span><span class="lineNoCov">          0 :         uvm_map_setup(&amp;kernel_map_store, base, end,</span>
<span class="lineNum">     172 </span>            : #ifdef KVA_GUARDPAGES
<span class="lineNum">     173 </span>            :             VM_MAP_PAGEABLE | VM_MAP_GUARDPAGES
<span class="lineNum">     174 </span>            : #else
<span class="lineNum">     175 </span>            :             VM_MAP_PAGEABLE
<span class="lineNum">     176 </span>            : #endif
<span class="lineNum">     177 </span>            :             );
<span class="lineNum">     178 </span><span class="lineNoCov">          0 :         kernel_map_store.pmap = pmap_kernel();</span>
<span class="lineNum">     179 </span><span class="lineNoCov">          0 :         if (base != start &amp;&amp; uvm_map(&amp;kernel_map_store, &amp;base, start - base,</span>
<span class="lineNum">     180 </span>            :             NULL, UVM_UNKNOWN_OFFSET, 0,
<span class="lineNum">     181 </span>            :             UVM_MAPFLAG(PROT_READ | PROT_WRITE, PROT_READ | PROT_WRITE,
<span class="lineNum">     182 </span><span class="lineNoCov">          0 :             MAP_INHERIT_NONE, MADV_RANDOM, UVM_FLAG_FIXED)) != 0)</span>
<span class="lineNum">     183 </span><span class="lineNoCov">          0 :                 panic(&quot;uvm_km_init: could not reserve space for kernel&quot;);</span>
<span class="lineNum">     184 </span>            :         
<span class="lineNum">     185 </span><span class="lineNoCov">          0 :         kernel_map = &amp;kernel_map_store;</span>
<span class="lineNum">     186 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     187 </span>            : 
<span class="lineNum">     188 </span>            : /*
<span class="lineNum">     189 </span>            :  * uvm_km_suballoc: allocate a submap in the kernel map.   once a submap
<span class="lineNum">     190 </span>            :  * is allocated all references to that area of VM must go through it.  this
<span class="lineNum">     191 </span>            :  * allows the locking of VAs in kernel_map to be broken up into regions.
<span class="lineNum">     192 </span>            :  *
<span class="lineNum">     193 </span>            :  * =&gt; if `fixed' is true, *min specifies where the region described
<span class="lineNum">     194 </span>            :  *      by the submap must start
<span class="lineNum">     195 </span>            :  * =&gt; if submap is non NULL we use that as the submap, otherwise we
<span class="lineNum">     196 </span>            :  *      alloc a new map
<a name="197"><span class="lineNum">     197 </span>            :  */</a>
<span class="lineNum">     198 </span>            : struct vm_map *
<span class="lineNum">     199 </span><span class="lineNoCov">          0 : uvm_km_suballoc(struct vm_map *map, vaddr_t *min, vaddr_t *max, vsize_t size,</span>
<span class="lineNum">     200 </span>            :     int flags, boolean_t fixed, struct vm_map *submap)
<span class="lineNum">     201 </span>            : {
<span class="lineNum">     202 </span><span class="lineNoCov">          0 :         int mapflags = UVM_FLAG_NOMERGE | (fixed ? UVM_FLAG_FIXED : 0);</span>
<span class="lineNum">     203 </span>            : 
<span class="lineNum">     204 </span><span class="lineNoCov">          0 :         size = round_page(size);        /* round up to pagesize */</span>
<span class="lineNum">     205 </span>            : 
<span class="lineNum">     206 </span>            :         /* first allocate a blank spot in the parent map */
<span class="lineNum">     207 </span><span class="lineNoCov">          0 :         if (uvm_map(map, min, size, NULL, UVM_UNKNOWN_OFFSET, 0,</span>
<span class="lineNum">     208 </span><span class="lineNoCov">          0 :             UVM_MAPFLAG(PROT_READ | PROT_WRITE, PROT_READ | PROT_WRITE,</span>
<span class="lineNum">     209 </span><span class="lineNoCov">          0 :             MAP_INHERIT_NONE, MADV_RANDOM, mapflags)) != 0) {</span>
<span class="lineNum">     210 </span><span class="lineNoCov">          0 :                panic(&quot;uvm_km_suballoc: unable to allocate space in parent map&quot;);</span>
<span class="lineNum">     211 </span>            :         }
<span class="lineNum">     212 </span>            : 
<span class="lineNum">     213 </span>            :         /* set VM bounds (min is filled in by uvm_map) */
<span class="lineNum">     214 </span><span class="lineNoCov">          0 :         *max = *min + size;</span>
<span class="lineNum">     215 </span>            : 
<span class="lineNum">     216 </span>            :         /* add references to pmap and create or init the submap */
<span class="lineNum">     217 </span><span class="lineNoCov">          0 :         pmap_reference(vm_map_pmap(map));</span>
<span class="lineNum">     218 </span><span class="lineNoCov">          0 :         if (submap == NULL) {</span>
<span class="lineNum">     219 </span><span class="lineNoCov">          0 :                 submap = uvm_map_create(vm_map_pmap(map), *min, *max, flags);</span>
<span class="lineNum">     220 </span><span class="lineNoCov">          0 :                 if (submap == NULL)</span>
<span class="lineNum">     221 </span><span class="lineNoCov">          0 :                         panic(&quot;uvm_km_suballoc: unable to create submap&quot;);</span>
<span class="lineNum">     222 </span>            :         } else {
<span class="lineNum">     223 </span><span class="lineNoCov">          0 :                 uvm_map_setup(submap, *min, *max, flags);</span>
<span class="lineNum">     224 </span><span class="lineNoCov">          0 :                 submap-&gt;pmap = vm_map_pmap(map);</span>
<span class="lineNum">     225 </span>            :         }
<span class="lineNum">     226 </span>            : 
<span class="lineNum">     227 </span>            :         /* now let uvm_map_submap plug in it...  */
<span class="lineNum">     228 </span><span class="lineNoCov">          0 :         if (uvm_map_submap(map, *min, *max, submap) != 0)</span>
<span class="lineNum">     229 </span><span class="lineNoCov">          0 :                 panic(&quot;uvm_km_suballoc: submap allocation failed&quot;);</span>
<span class="lineNum">     230 </span>            : 
<span class="lineNum">     231 </span><span class="lineNoCov">          0 :         return(submap);</span>
<span class="lineNum">     232 </span>            : }
<span class="lineNum">     233 </span>            : 
<span class="lineNum">     234 </span>            : /*
<span class="lineNum">     235 </span>            :  * uvm_km_pgremove: remove pages from a kernel uvm_object.
<span class="lineNum">     236 </span>            :  *
<span class="lineNum">     237 </span>            :  * =&gt; when you unmap a part of anonymous kernel memory you want to toss
<span class="lineNum">     238 </span>            :  *    the pages right away.    (this gets called from uvm_unmap_...).
<a name="239"><span class="lineNum">     239 </span>            :  */</a>
<span class="lineNum">     240 </span>            : void
<span class="lineNum">     241 </span><span class="lineNoCov">          0 : uvm_km_pgremove(struct uvm_object *uobj, vaddr_t start, vaddr_t end)</span>
<span class="lineNum">     242 </span>            : {
<span class="lineNum">     243 </span>            :         struct vm_page *pp;
<span class="lineNum">     244 </span>            :         voff_t curoff;
<span class="lineNum">     245 </span>            :         int slot;
<span class="lineNum">     246 </span>            : 
<span class="lineNum">     247 </span><span class="lineNoCov">          0 :         KASSERT(uobj-&gt;pgops == &amp;aobj_pager);</span>
<span class="lineNum">     248 </span>            : 
<span class="lineNum">     249 </span><span class="lineNoCov">          0 :         for (curoff = start ; curoff &lt; end ; curoff += PAGE_SIZE) {</span>
<span class="lineNum">     250 </span><span class="lineNoCov">          0 :                 pp = uvm_pagelookup(uobj, curoff);</span>
<span class="lineNum">     251 </span><span class="lineNoCov">          0 :                 if (pp &amp;&amp; pp-&gt;pg_flags &amp; PG_BUSY) {</span>
<span class="lineNum">     252 </span><span class="lineNoCov">          0 :                         atomic_setbits_int(&amp;pp-&gt;pg_flags, PG_WANTED);</span>
<span class="lineNum">     253 </span><span class="lineNoCov">          0 :                         UVM_WAIT(pp, 0, &quot;km_pgrm&quot;, 0);</span>
<span class="lineNum">     254 </span><span class="lineNoCov">          0 :                         curoff -= PAGE_SIZE; /* loop back to us */</span>
<span class="lineNum">     255 </span><span class="lineNoCov">          0 :                         continue;</span>
<span class="lineNum">     256 </span>            :                 }
<span class="lineNum">     257 </span>            : 
<span class="lineNum">     258 </span>            :                 /* free the swap slot, then the page */
<span class="lineNum">     259 </span><span class="lineNoCov">          0 :                 slot = uao_dropswap(uobj, curoff &gt;&gt; PAGE_SHIFT);</span>
<span class="lineNum">     260 </span>            : 
<span class="lineNum">     261 </span><span class="lineNoCov">          0 :                 if (pp != NULL) {</span>
<span class="lineNum">     262 </span><span class="lineNoCov">          0 :                         uvm_lock_pageq();</span>
<span class="lineNum">     263 </span><span class="lineNoCov">          0 :                         uvm_pagefree(pp);</span>
<span class="lineNum">     264 </span><span class="lineNoCov">          0 :                         uvm_unlock_pageq();</span>
<span class="lineNum">     265 </span><span class="lineNoCov">          0 :                 } else if (slot != 0) {</span>
<span class="lineNum">     266 </span><span class="lineNoCov">          0 :                         uvmexp.swpgonly--;</span>
<span class="lineNum">     267 </span><span class="lineNoCov">          0 :                 }</span>
<span class="lineNum">     268 </span>            :         }
<span class="lineNum">     269 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     270 </span>            : 
<span class="lineNum">     271 </span>            : 
<span class="lineNum">     272 </span>            : /*
<span class="lineNum">     273 </span>            :  * uvm_km_pgremove_intrsafe: like uvm_km_pgremove(), but for &quot;intrsafe&quot;
<span class="lineNum">     274 </span>            :  *    objects
<span class="lineNum">     275 </span>            :  *
<span class="lineNum">     276 </span>            :  * =&gt; when you unmap a part of anonymous kernel memory you want to toss
<span class="lineNum">     277 </span>            :  *    the pages right away.    (this gets called from uvm_unmap_...).
<span class="lineNum">     278 </span>            :  * =&gt; none of the pages will ever be busy, and none of them will ever
<span class="lineNum">     279 </span>            :  *    be on the active or inactive queues (because these objects are
<span class="lineNum">     280 </span>            :  *    never allowed to &quot;page&quot;).
<a name="281"><span class="lineNum">     281 </span>            :  */</a>
<span class="lineNum">     282 </span>            : void
<span class="lineNum">     283 </span><span class="lineNoCov">          0 : uvm_km_pgremove_intrsafe(vaddr_t start, vaddr_t end)</span>
<span class="lineNum">     284 </span>            : {
<span class="lineNum">     285 </span>            :         struct vm_page *pg;
<span class="lineNum">     286 </span>            :         vaddr_t va;
<span class="lineNum">     287 </span><span class="lineNoCov">          0 :         paddr_t pa;</span>
<span class="lineNum">     288 </span>            : 
<span class="lineNum">     289 </span><span class="lineNoCov">          0 :         for (va = start; va &lt; end; va += PAGE_SIZE) {</span>
<span class="lineNum">     290 </span><span class="lineNoCov">          0 :                 if (!pmap_extract(pmap_kernel(), va, &amp;pa))</span>
<span class="lineNum">     291 </span>            :                         continue;
<span class="lineNum">     292 </span><span class="lineNoCov">          0 :                 pg = PHYS_TO_VM_PAGE(pa);</span>
<span class="lineNum">     293 </span><span class="lineNoCov">          0 :                 if (pg == NULL)</span>
<span class="lineNum">     294 </span><span class="lineNoCov">          0 :                         panic(&quot;uvm_km_pgremove_intrsafe: no page&quot;);</span>
<span class="lineNum">     295 </span><span class="lineNoCov">          0 :                 uvm_pagefree(pg);</span>
<span class="lineNum">     296 </span><span class="lineNoCov">          0 :         }</span>
<span class="lineNum">     297 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     298 </span>            : 
<span class="lineNum">     299 </span>            : /*
<span class="lineNum">     300 </span>            :  * uvm_km_kmemalloc: lower level kernel memory allocator for malloc()
<span class="lineNum">     301 </span>            :  *
<span class="lineNum">     302 </span>            :  * =&gt; we map wired memory into the specified map using the obj passed in
<span class="lineNum">     303 </span>            :  * =&gt; NOTE: we can return NULL even if we can wait if there is not enough
<span class="lineNum">     304 </span>            :  *      free VM space in the map... caller should be prepared to handle
<span class="lineNum">     305 </span>            :  *      this case.
<span class="lineNum">     306 </span>            :  * =&gt; we return KVA of memory allocated
<span class="lineNum">     307 </span>            :  * =&gt; flags: NOWAIT, VALLOC - just allocate VA, TRYLOCK - fail if we can't
<span class="lineNum">     308 </span>            :  *      lock the map
<span class="lineNum">     309 </span>            :  * =&gt; low, high, alignment, boundary, nsegs are the corresponding parameters
<span class="lineNum">     310 </span>            :  *      to uvm_pglistalloc
<span class="lineNum">     311 </span>            :  * =&gt; flags: ZERO - correspond to uvm_pglistalloc flags
<a name="312"><span class="lineNum">     312 </span>            :  */</a>
<span class="lineNum">     313 </span>            : vaddr_t
<span class="lineNum">     314 </span><span class="lineNoCov">          0 : uvm_km_kmemalloc_pla(struct vm_map *map, struct uvm_object *obj, vsize_t size,</span>
<span class="lineNum">     315 </span>            :     vsize_t valign, int flags, paddr_t low, paddr_t high, paddr_t alignment,
<span class="lineNum">     316 </span>            :     paddr_t boundary, int nsegs)
<span class="lineNum">     317 </span>            : {
<span class="lineNum">     318 </span><span class="lineNoCov">          0 :         vaddr_t kva, loopva;</span>
<span class="lineNum">     319 </span>            :         voff_t offset;
<span class="lineNum">     320 </span>            :         struct vm_page *pg;
<span class="lineNum">     321 </span><span class="lineNoCov">          0 :         struct pglist pgl;</span>
<span class="lineNum">     322 </span>            :         int pla_flags;
<span class="lineNum">     323 </span>            : 
<span class="lineNum">     324 </span><span class="lineNoCov">          0 :         KASSERT(vm_map_pmap(map) == pmap_kernel());</span>
<span class="lineNum">     325 </span>            :         /* UVM_KMF_VALLOC =&gt; !UVM_KMF_ZERO */
<span class="lineNum">     326 </span><span class="lineNoCov">          0 :         KASSERT(!(flags &amp; UVM_KMF_VALLOC) ||</span>
<span class="lineNum">     327 </span>            :             !(flags &amp; UVM_KMF_ZERO));
<span class="lineNum">     328 </span>            : 
<span class="lineNum">     329 </span>            :         /* setup for call */
<span class="lineNum">     330 </span><span class="lineNoCov">          0 :         size = round_page(size);</span>
<span class="lineNum">     331 </span><span class="lineNoCov">          0 :         kva = vm_map_min(map);  /* hint */</span>
<span class="lineNum">     332 </span><span class="lineNoCov">          0 :         if (nsegs == 0)</span>
<span class="lineNum">     333 </span><span class="lineNoCov">          0 :                 nsegs = atop(size);</span>
<span class="lineNum">     334 </span>            : 
<span class="lineNum">     335 </span>            :         /* allocate some virtual space */
<span class="lineNum">     336 </span><span class="lineNoCov">          0 :         if (__predict_false(uvm_map(map, &amp;kva, size, obj, UVM_UNKNOWN_OFFSET,</span>
<span class="lineNum">     337 </span>            :             valign, UVM_MAPFLAG(PROT_READ | PROT_WRITE, PROT_READ | PROT_WRITE,
<span class="lineNum">     338 </span>            :             MAP_INHERIT_NONE, MADV_RANDOM, (flags &amp; UVM_KMF_TRYLOCK))) != 0)) {
<span class="lineNum">     339 </span><span class="lineNoCov">          0 :                 return(0);</span>
<span class="lineNum">     340 </span>            :         }
<span class="lineNum">     341 </span>            : 
<span class="lineNum">     342 </span>            :         /* if all we wanted was VA, return now */
<span class="lineNum">     343 </span><span class="lineNoCov">          0 :         if (flags &amp; UVM_KMF_VALLOC) {</span>
<span class="lineNum">     344 </span><span class="lineNoCov">          0 :                 return(kva);</span>
<span class="lineNum">     345 </span>            :         }
<span class="lineNum">     346 </span>            : 
<span class="lineNum">     347 </span>            :         /* recover object offset from virtual address */
<span class="lineNum">     348 </span><span class="lineNoCov">          0 :         if (obj != NULL)</span>
<span class="lineNum">     349 </span><span class="lineNoCov">          0 :                 offset = kva - vm_map_min(kernel_map);</span>
<span class="lineNum">     350 </span>            :         else
<span class="lineNum">     351 </span>            :                 offset = 0;
<span class="lineNum">     352 </span>            : 
<span class="lineNum">     353 </span>            :         /*
<span class="lineNum">     354 </span>            :          * now allocate and map in the memory... note that we are the only ones
<span class="lineNum">     355 </span>            :          * whom should ever get a handle on this area of VM.
<span class="lineNum">     356 </span>            :          */
<span class="lineNum">     357 </span><span class="lineNoCov">          0 :         TAILQ_INIT(&amp;pgl);</span>
<span class="lineNum">     358 </span>            :         pla_flags = 0;
<span class="lineNum">     359 </span><span class="lineNoCov">          0 :         KASSERT(uvmexp.swpgonly &lt;= uvmexp.swpages);</span>
<span class="lineNum">     360 </span><span class="lineNoCov">          0 :         if ((flags &amp; UVM_KMF_NOWAIT) ||</span>
<span class="lineNum">     361 </span><span class="lineNoCov">          0 :             ((flags &amp; UVM_KMF_CANFAIL) &amp;&amp;</span>
<span class="lineNum">     362 </span><span class="lineNoCov">          0 :             uvmexp.swpages - uvmexp.swpgonly &lt;= atop(size)))</span>
<span class="lineNum">     363 </span><span class="lineNoCov">          0 :                 pla_flags |= UVM_PLA_NOWAIT;</span>
<span class="lineNum">     364 </span>            :         else
<span class="lineNum">     365 </span>            :                 pla_flags |= UVM_PLA_WAITOK;
<span class="lineNum">     366 </span><span class="lineNoCov">          0 :         if (flags &amp; UVM_KMF_ZERO)</span>
<span class="lineNum">     367 </span><span class="lineNoCov">          0 :                 pla_flags |= UVM_PLA_ZERO;</span>
<span class="lineNum">     368 </span><span class="lineNoCov">          0 :         if (uvm_pglistalloc(size, low, high, alignment, boundary, &amp;pgl, nsegs,</span>
<span class="lineNum">     369 </span><span class="lineNoCov">          0 :             pla_flags) != 0) {</span>
<span class="lineNum">     370 </span>            :                 /* Failed. */
<span class="lineNum">     371 </span><span class="lineNoCov">          0 :                 uvm_unmap(map, kva, kva + size);</span>
<span class="lineNum">     372 </span><span class="lineNoCov">          0 :                 return (0);</span>
<span class="lineNum">     373 </span>            :         }
<span class="lineNum">     374 </span>            : 
<span class="lineNum">     375 </span><span class="lineNoCov">          0 :         loopva = kva;</span>
<span class="lineNum">     376 </span><span class="lineNoCov">          0 :         while (loopva != kva + size) {</span>
<span class="lineNum">     377 </span>            :                 pg = TAILQ_FIRST(&amp;pgl);
<span class="lineNum">     378 </span><span class="lineNoCov">          0 :                 TAILQ_REMOVE(&amp;pgl, pg, pageq);</span>
<span class="lineNum">     379 </span><span class="lineNoCov">          0 :                 uvm_pagealloc_pg(pg, obj, offset, NULL);</span>
<span class="lineNum">     380 </span><span class="lineNoCov">          0 :                 atomic_clearbits_int(&amp;pg-&gt;pg_flags, PG_BUSY);</span>
<span class="lineNum">     381 </span>            :                 UVM_PAGE_OWN(pg, NULL);
<span class="lineNum">     382 </span>            : 
<span class="lineNum">     383 </span>            :                 /*
<span class="lineNum">     384 </span>            :                  * map it in: note that we call pmap_enter with the map and
<span class="lineNum">     385 </span>            :                  * object unlocked in case we are kmem_map.
<span class="lineNum">     386 </span>            :                  */
<span class="lineNum">     387 </span><span class="lineNoCov">          0 :                 if (obj == NULL) {</span>
<span class="lineNum">     388 </span><span class="lineNoCov">          0 :                         pmap_kenter_pa(loopva, VM_PAGE_TO_PHYS(pg),</span>
<span class="lineNum">     389 </span>            :                             PROT_READ | PROT_WRITE);
<span class="lineNum">     390 </span><span class="lineNoCov">          0 :                 } else {</span>
<span class="lineNum">     391 </span><span class="lineNoCov">          0 :                         pmap_enter(map-&gt;pmap, loopva, VM_PAGE_TO_PHYS(pg),</span>
<span class="lineNum">     392 </span>            :                             PROT_READ | PROT_WRITE,
<span class="lineNum">     393 </span>            :                             PROT_READ | PROT_WRITE | PMAP_WIRED);
<span class="lineNum">     394 </span>            :                 }
<span class="lineNum">     395 </span><span class="lineNoCov">          0 :                 loopva += PAGE_SIZE;</span>
<span class="lineNum">     396 </span><span class="lineNoCov">          0 :                 offset += PAGE_SIZE;</span>
<span class="lineNum">     397 </span>            :         }
<span class="lineNum">     398 </span><span class="lineNoCov">          0 :         KASSERT(TAILQ_EMPTY(&amp;pgl));</span>
<span class="lineNum">     399 </span>            :         pmap_update(pmap_kernel());
<span class="lineNum">     400 </span>            : 
<span class="lineNum">     401 </span><span class="lineNoCov">          0 :         return(kva);</span>
<span class="lineNum">     402 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     403 </span>            : 
<span class="lineNum">     404 </span>            : /*
<span class="lineNum">     405 </span>            :  * uvm_km_free: free an area of kernel memory
<a name="406"><span class="lineNum">     406 </span>            :  */</a>
<span class="lineNum">     407 </span>            : void
<span class="lineNum">     408 </span><span class="lineNoCov">          0 : uvm_km_free(struct vm_map *map, vaddr_t addr, vsize_t size)</span>
<span class="lineNum">     409 </span>            : {
<span class="lineNum">     410 </span><span class="lineNoCov">          0 :         uvm_unmap(map, trunc_page(addr), round_page(addr+size));</span>
<span class="lineNum">     411 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     412 </span>            : 
<span class="lineNum">     413 </span>            : /*
<span class="lineNum">     414 </span>            :  * uvm_km_free_wakeup: free an area of kernel memory and wake up
<span class="lineNum">     415 </span>            :  * anyone waiting for vm space.
<span class="lineNum">     416 </span>            :  *
<span class="lineNum">     417 </span>            :  * =&gt; XXX: &quot;wanted&quot; bit + unlock&amp;wait on other end?
<a name="418"><span class="lineNum">     418 </span>            :  */</a>
<span class="lineNum">     419 </span>            : void
<span class="lineNum">     420 </span><span class="lineNoCov">          0 : uvm_km_free_wakeup(struct vm_map *map, vaddr_t addr, vsize_t size)</span>
<span class="lineNum">     421 </span>            : {
<span class="lineNum">     422 </span><span class="lineNoCov">          0 :         struct uvm_map_deadq dead_entries;</span>
<span class="lineNum">     423 </span>            : 
<span class="lineNum">     424 </span><span class="lineNoCov">          0 :         vm_map_lock(map);</span>
<span class="lineNum">     425 </span><span class="lineNoCov">          0 :         TAILQ_INIT(&amp;dead_entries);</span>
<span class="lineNum">     426 </span><span class="lineNoCov">          0 :         uvm_unmap_remove(map, trunc_page(addr), round_page(addr+size), </span>
<span class="lineNum">     427 </span>            :              &amp;dead_entries, FALSE, TRUE);
<span class="lineNum">     428 </span><span class="lineNoCov">          0 :         wakeup(map);</span>
<span class="lineNum">     429 </span><span class="lineNoCov">          0 :         vm_map_unlock(map);</span>
<span class="lineNum">     430 </span>            : 
<span class="lineNum">     431 </span><span class="lineNoCov">          0 :         uvm_unmap_detach(&amp;dead_entries, 0);</span>
<span class="lineNum">     432 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     433 </span>            : 
<span class="lineNum">     434 </span>            : /*
<span class="lineNum">     435 </span>            :  * uvm_km_alloc1: allocate wired down memory in the kernel map.
<span class="lineNum">     436 </span>            :  *
<span class="lineNum">     437 </span>            :  * =&gt; we can sleep if needed
<a name="438"><span class="lineNum">     438 </span>            :  */</a>
<span class="lineNum">     439 </span>            : vaddr_t
<span class="lineNum">     440 </span><span class="lineNoCov">          0 : uvm_km_alloc1(struct vm_map *map, vsize_t size, vsize_t align, boolean_t zeroit)</span>
<span class="lineNum">     441 </span>            : {
<span class="lineNum">     442 </span><span class="lineNoCov">          0 :         vaddr_t kva, loopva;</span>
<span class="lineNum">     443 </span>            :         voff_t offset;
<span class="lineNum">     444 </span>            :         struct vm_page *pg;
<span class="lineNum">     445 </span>            : 
<span class="lineNum">     446 </span><span class="lineNoCov">          0 :         KASSERT(vm_map_pmap(map) == pmap_kernel());</span>
<span class="lineNum">     447 </span>            : 
<span class="lineNum">     448 </span><span class="lineNoCov">          0 :         size = round_page(size);</span>
<span class="lineNum">     449 </span><span class="lineNoCov">          0 :         kva = vm_map_min(map);          /* hint */</span>
<span class="lineNum">     450 </span>            : 
<span class="lineNum">     451 </span>            :         /* allocate some virtual space */
<span class="lineNum">     452 </span><span class="lineNoCov">          0 :         if (__predict_false(uvm_map(map, &amp;kva, size, uvm.kernel_object,</span>
<span class="lineNum">     453 </span>            :             UVM_UNKNOWN_OFFSET, align,
<span class="lineNum">     454 </span>            :             UVM_MAPFLAG(PROT_READ | PROT_WRITE,
<span class="lineNum">     455 </span>            :             PROT_READ | PROT_WRITE | PROT_EXEC,
<span class="lineNum">     456 </span>            :             MAP_INHERIT_NONE, MADV_RANDOM, 0)) != 0)) {
<span class="lineNum">     457 </span><span class="lineNoCov">          0 :                 return(0);</span>
<span class="lineNum">     458 </span>            :         }
<span class="lineNum">     459 </span>            : 
<span class="lineNum">     460 </span>            :         /* recover object offset from virtual address */
<span class="lineNum">     461 </span><span class="lineNoCov">          0 :         offset = kva - vm_map_min(kernel_map);</span>
<span class="lineNum">     462 </span>            : 
<span class="lineNum">     463 </span>            :         /* now allocate the memory.  we must be careful about released pages. */
<span class="lineNum">     464 </span>            :         loopva = kva;
<span class="lineNum">     465 </span><span class="lineNoCov">          0 :         while (size) {</span>
<span class="lineNum">     466 </span>            :                 /* allocate ram */
<span class="lineNum">     467 </span><span class="lineNoCov">          0 :                 pg = uvm_pagealloc(uvm.kernel_object, offset, NULL, 0);</span>
<span class="lineNum">     468 </span><span class="lineNoCov">          0 :                 if (pg) {</span>
<span class="lineNum">     469 </span><span class="lineNoCov">          0 :                         atomic_clearbits_int(&amp;pg-&gt;pg_flags, PG_BUSY);</span>
<span class="lineNum">     470 </span>            :                         UVM_PAGE_OWN(pg, NULL);
<span class="lineNum">     471 </span><span class="lineNoCov">          0 :                 }</span>
<span class="lineNum">     472 </span><span class="lineNoCov">          0 :                 if (__predict_false(pg == NULL)) {</span>
<span class="lineNum">     473 </span><span class="lineNoCov">          0 :                         if (curproc == uvm.pagedaemon_proc) {</span>
<span class="lineNum">     474 </span>            :                                 /*
<span class="lineNum">     475 </span>            :                                  * It is unfeasible for the page daemon to
<span class="lineNum">     476 </span>            :                                  * sleep for memory, so free what we have
<span class="lineNum">     477 </span>            :                                  * allocated and fail.
<span class="lineNum">     478 </span>            :                                  */
<span class="lineNum">     479 </span><span class="lineNoCov">          0 :                                 uvm_unmap(map, kva, loopva - kva);</span>
<span class="lineNum">     480 </span><span class="lineNoCov">          0 :                                 return (0);</span>
<span class="lineNum">     481 </span>            :                         } else {
<span class="lineNum">     482 </span><span class="lineNoCov">          0 :                                 uvm_wait(&quot;km_alloc1w&quot;);       /* wait for memory */</span>
<span class="lineNum">     483 </span><span class="lineNoCov">          0 :                                 continue;</span>
<span class="lineNum">     484 </span>            :                         }
<span class="lineNum">     485 </span>            :                 }
<span class="lineNum">     486 </span>            : 
<span class="lineNum">     487 </span>            :                 /*
<span class="lineNum">     488 </span>            :                  * map it in; note we're never called with an intrsafe
<span class="lineNum">     489 </span>            :                  * object, so we always use regular old pmap_enter().
<span class="lineNum">     490 </span>            :                  */
<span class="lineNum">     491 </span><span class="lineNoCov">          0 :                 pmap_enter(map-&gt;pmap, loopva, VM_PAGE_TO_PHYS(pg),</span>
<span class="lineNum">     492 </span>            :                     PROT_READ | PROT_WRITE,
<span class="lineNum">     493 </span>            :                     PROT_READ | PROT_WRITE | PMAP_WIRED);
<span class="lineNum">     494 </span>            : 
<span class="lineNum">     495 </span><span class="lineNoCov">          0 :                 loopva += PAGE_SIZE;</span>
<span class="lineNum">     496 </span><span class="lineNoCov">          0 :                 offset += PAGE_SIZE;</span>
<span class="lineNum">     497 </span><span class="lineNoCov">          0 :                 size -= PAGE_SIZE;</span>
<span class="lineNum">     498 </span>            :         }
<span class="lineNum">     499 </span>            :         pmap_update(map-&gt;pmap);
<span class="lineNum">     500 </span>            :         
<span class="lineNum">     501 </span>            :         /*
<span class="lineNum">     502 </span>            :          * zero on request (note that &quot;size&quot; is now zero due to the above loop
<span class="lineNum">     503 </span>            :          * so we need to subtract kva from loopva to reconstruct the size).
<span class="lineNum">     504 </span>            :          */
<span class="lineNum">     505 </span><span class="lineNoCov">          0 :         if (zeroit)</span>
<span class="lineNum">     506 </span><span class="lineNoCov">          0 :                 memset((caddr_t)kva, 0, loopva - kva);</span>
<span class="lineNum">     507 </span>            : 
<span class="lineNum">     508 </span><span class="lineNoCov">          0 :         return(kva);</span>
<span class="lineNum">     509 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     510 </span>            : 
<span class="lineNum">     511 </span>            : /*
<span class="lineNum">     512 </span>            :  * uvm_km_valloc: allocate zero-fill memory in the kernel's address space
<span class="lineNum">     513 </span>            :  *
<span class="lineNum">     514 </span>            :  * =&gt; memory is not allocated until fault time
<span class="lineNum">     515 </span>            :  */
<a name="516"><span class="lineNum">     516 </span>            : </a>
<span class="lineNum">     517 </span>            : vaddr_t
<span class="lineNum">     518 </span><span class="lineNoCov">          0 : uvm_km_valloc(struct vm_map *map, vsize_t size)</span>
<span class="lineNum">     519 </span>            : {
<span class="lineNum">     520 </span><span class="lineNoCov">          0 :         return(uvm_km_valloc_align(map, size, 0, 0));</span>
<span class="lineNum">     521 </span>            : }
<a name="522"><span class="lineNum">     522 </span>            : </a>
<span class="lineNum">     523 </span>            : vaddr_t
<span class="lineNum">     524 </span><span class="lineNoCov">          0 : uvm_km_valloc_try(struct vm_map *map, vsize_t size)</span>
<span class="lineNum">     525 </span>            : {
<span class="lineNum">     526 </span><span class="lineNoCov">          0 :         return(uvm_km_valloc_align(map, size, 0, UVM_FLAG_TRYLOCK));</span>
<span class="lineNum">     527 </span>            : }
<a name="528"><span class="lineNum">     528 </span>            : </a>
<span class="lineNum">     529 </span>            : vaddr_t
<span class="lineNum">     530 </span><span class="lineNoCov">          0 : uvm_km_valloc_align(struct vm_map *map, vsize_t size, vsize_t align, int flags)</span>
<span class="lineNum">     531 </span>            : {
<span class="lineNum">     532 </span><span class="lineNoCov">          0 :         vaddr_t kva;</span>
<span class="lineNum">     533 </span>            : 
<span class="lineNum">     534 </span><span class="lineNoCov">          0 :         KASSERT(vm_map_pmap(map) == pmap_kernel());</span>
<span class="lineNum">     535 </span>            : 
<span class="lineNum">     536 </span><span class="lineNoCov">          0 :         size = round_page(size);</span>
<span class="lineNum">     537 </span><span class="lineNoCov">          0 :         kva = vm_map_min(map);          /* hint */</span>
<span class="lineNum">     538 </span>            : 
<span class="lineNum">     539 </span>            :         /* allocate some virtual space, demand filled by kernel_object. */
<span class="lineNum">     540 </span>            : 
<span class="lineNum">     541 </span><span class="lineNoCov">          0 :         if (__predict_false(uvm_map(map, &amp;kva, size, uvm.kernel_object,</span>
<span class="lineNum">     542 </span>            :             UVM_UNKNOWN_OFFSET, align,
<span class="lineNum">     543 </span>            :             UVM_MAPFLAG(PROT_READ | PROT_WRITE, PROT_READ | PROT_WRITE,
<span class="lineNum">     544 </span>            :             MAP_INHERIT_NONE, MADV_RANDOM, flags)) != 0)) {
<span class="lineNum">     545 </span><span class="lineNoCov">          0 :                 return(0);</span>
<span class="lineNum">     546 </span>            :         }
<span class="lineNum">     547 </span>            : 
<span class="lineNum">     548 </span><span class="lineNoCov">          0 :         return(kva);</span>
<span class="lineNum">     549 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     550 </span>            : 
<span class="lineNum">     551 </span>            : /*
<span class="lineNum">     552 </span>            :  * uvm_km_valloc_wait: allocate zero-fill memory in the kernel's address space
<span class="lineNum">     553 </span>            :  *
<span class="lineNum">     554 </span>            :  * =&gt; memory is not allocated until fault time
<span class="lineNum">     555 </span>            :  * =&gt; if no room in map, wait for space to free, unless requested size
<span class="lineNum">     556 </span>            :  *    is larger than map (in which case we return 0)
<a name="557"><span class="lineNum">     557 </span>            :  */</a>
<span class="lineNum">     558 </span>            : vaddr_t
<span class="lineNum">     559 </span><span class="lineNoCov">          0 : uvm_km_valloc_prefer_wait(struct vm_map *map, vsize_t size, voff_t prefer)</span>
<span class="lineNum">     560 </span>            : {
<span class="lineNum">     561 </span><span class="lineNoCov">          0 :         vaddr_t kva;</span>
<span class="lineNum">     562 </span>            : 
<span class="lineNum">     563 </span><span class="lineNoCov">          0 :         KASSERT(vm_map_pmap(map) == pmap_kernel());</span>
<span class="lineNum">     564 </span>            : 
<span class="lineNum">     565 </span><span class="lineNoCov">          0 :         size = round_page(size);</span>
<span class="lineNum">     566 </span><span class="lineNoCov">          0 :         if (size &gt; vm_map_max(map) - vm_map_min(map))</span>
<span class="lineNum">     567 </span><span class="lineNoCov">          0 :                 return(0);</span>
<span class="lineNum">     568 </span>            : 
<span class="lineNum">     569 </span><span class="lineNoCov">          0 :         while (1) {</span>
<span class="lineNum">     570 </span><span class="lineNoCov">          0 :                 kva = vm_map_min(map);          /* hint */</span>
<span class="lineNum">     571 </span>            : 
<span class="lineNum">     572 </span>            :                 /*
<span class="lineNum">     573 </span>            :                  * allocate some virtual space.   will be demand filled
<span class="lineNum">     574 </span>            :                  * by kernel_object.
<span class="lineNum">     575 </span>            :                  */
<span class="lineNum">     576 </span><span class="lineNoCov">          0 :                 if (__predict_true(uvm_map(map, &amp;kva, size, uvm.kernel_object,</span>
<span class="lineNum">     577 </span>            :                     prefer, 0,
<span class="lineNum">     578 </span>            :                     UVM_MAPFLAG(PROT_READ | PROT_WRITE, PROT_READ | PROT_WRITE,
<span class="lineNum">     579 </span>            :                     MAP_INHERIT_NONE, MADV_RANDOM, 0)) == 0)) {
<span class="lineNum">     580 </span><span class="lineNoCov">          0 :                         return(kva);</span>
<span class="lineNum">     581 </span>            :                 }
<span class="lineNum">     582 </span>            : 
<span class="lineNum">     583 </span>            :                 /* failed.  sleep for a while (on map) */
<span class="lineNum">     584 </span><span class="lineNoCov">          0 :                 tsleep(map, PVM, &quot;vallocwait&quot;, 0);</span>
<span class="lineNum">     585 </span>            :         }
<span class="lineNum">     586 </span>            :         /*NOTREACHED*/
<span class="lineNum">     587 </span><span class="lineNoCov">          0 : }</span>
<a name="588"><span class="lineNum">     588 </span>            : </a>
<span class="lineNum">     589 </span>            : vaddr_t
<span class="lineNum">     590 </span><span class="lineNoCov">          0 : uvm_km_valloc_wait(struct vm_map *map, vsize_t size)</span>
<span class="lineNum">     591 </span>            : {
<span class="lineNum">     592 </span><span class="lineNoCov">          0 :         return uvm_km_valloc_prefer_wait(map, size, UVM_UNKNOWN_OFFSET);</span>
<span class="lineNum">     593 </span>            : }
<span class="lineNum">     594 </span>            : 
<span class="lineNum">     595 </span>            : #if defined(__HAVE_PMAP_DIRECT)
<span class="lineNum">     596 </span>            : /*
<span class="lineNum">     597 </span>            :  * uvm_km_page allocator, __HAVE_PMAP_DIRECT arch
<span class="lineNum">     598 </span>            :  * On architectures with machine memory direct mapped into a portion
<span class="lineNum">     599 </span>            :  * of KVM, we have very little work to do.  Just get a physical page,
<span class="lineNum">     600 </span>            :  * and find and return its VA.
<a name="601"><span class="lineNum">     601 </span>            :  */</a>
<span class="lineNum">     602 </span>            : void
<span class="lineNum">     603 </span><span class="lineNoCov">          0 : uvm_km_page_init(void)</span>
<span class="lineNum">     604 </span>            : {
<span class="lineNum">     605 </span>            :         /* nothing */
<span class="lineNum">     606 </span><span class="lineNoCov">          0 : }</span>
<a name="607"><span class="lineNum">     607 </span>            : </a>
<span class="lineNum">     608 </span>            : void
<span class="lineNum">     609 </span><span class="lineNoCov">          0 : uvm_km_page_lateinit(void)</span>
<span class="lineNum">     610 </span>            : {
<span class="lineNum">     611 </span>            :         /* nothing */
<span class="lineNum">     612 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     613 </span>            : 
<span class="lineNum">     614 </span>            : #else
<span class="lineNum">     615 </span>            : /*
<span class="lineNum">     616 </span>            :  * uvm_km_page allocator, non __HAVE_PMAP_DIRECT archs
<span class="lineNum">     617 </span>            :  * This is a special allocator that uses a reserve of free pages
<span class="lineNum">     618 </span>            :  * to fulfill requests.  It is fast and interrupt safe, but can only
<span class="lineNum">     619 </span>            :  * return page sized regions.  Its primary use is as a backend for pool.
<span class="lineNum">     620 </span>            :  *
<span class="lineNum">     621 </span>            :  * The memory returned is allocated from the larger kernel_map, sparing
<span class="lineNum">     622 </span>            :  * pressure on the small interrupt-safe kmem_map.  It is wired, but
<span class="lineNum">     623 </span>            :  * not zero filled.
<span class="lineNum">     624 </span>            :  */
<span class="lineNum">     625 </span>            : 
<span class="lineNum">     626 </span>            : struct uvm_km_pages uvm_km_pages;
<span class="lineNum">     627 </span>            : 
<span class="lineNum">     628 </span>            : void uvm_km_createthread(void *);
<span class="lineNum">     629 </span>            : void uvm_km_thread(void *);
<span class="lineNum">     630 </span>            : struct uvm_km_free_page *uvm_km_doputpage(struct uvm_km_free_page *);
<span class="lineNum">     631 </span>            : 
<span class="lineNum">     632 </span>            : /*
<span class="lineNum">     633 </span>            :  * Allocate the initial reserve, and create the thread which will
<span class="lineNum">     634 </span>            :  * keep the reserve full.  For bootstrapping, we allocate more than
<span class="lineNum">     635 </span>            :  * the lowat amount, because it may be a while before the thread is
<span class="lineNum">     636 </span>            :  * running.
<span class="lineNum">     637 </span>            :  */
<span class="lineNum">     638 </span>            : void
<span class="lineNum">     639 </span>            : uvm_km_page_init(void)
<span class="lineNum">     640 </span>            : {
<span class="lineNum">     641 </span>            :         int     lowat_min;
<span class="lineNum">     642 </span>            :         int     i;
<span class="lineNum">     643 </span>            :         int     len, bulk;
<span class="lineNum">     644 </span>            :         vaddr_t addr;
<span class="lineNum">     645 </span>            : 
<span class="lineNum">     646 </span>            :         mtx_init(&amp;uvm_km_pages.mtx, IPL_VM);
<span class="lineNum">     647 </span>            :         if (!uvm_km_pages.lowat) {
<span class="lineNum">     648 </span>            :                 /* based on physmem, calculate a good value here */
<span class="lineNum">     649 </span>            :                 uvm_km_pages.lowat = physmem / 256;
<span class="lineNum">     650 </span>            :                 lowat_min = physmem &lt; atop(16 * 1024 * 1024) ? 32 : 128;
<span class="lineNum">     651 </span>            :                 if (uvm_km_pages.lowat &lt; lowat_min)
<span class="lineNum">     652 </span>            :                         uvm_km_pages.lowat = lowat_min;
<span class="lineNum">     653 </span>            :         }
<span class="lineNum">     654 </span>            :         if (uvm_km_pages.lowat &gt; UVM_KM_PAGES_LOWAT_MAX)
<span class="lineNum">     655 </span>            :                 uvm_km_pages.lowat = UVM_KM_PAGES_LOWAT_MAX;
<span class="lineNum">     656 </span>            :         uvm_km_pages.hiwat = 4 * uvm_km_pages.lowat;
<span class="lineNum">     657 </span>            :         if (uvm_km_pages.hiwat &gt; UVM_KM_PAGES_HIWAT_MAX)
<span class="lineNum">     658 </span>            :                 uvm_km_pages.hiwat = UVM_KM_PAGES_HIWAT_MAX;
<span class="lineNum">     659 </span>            : 
<span class="lineNum">     660 </span>            :         /* Allocate all pages in as few allocations as possible. */
<span class="lineNum">     661 </span>            :         len = 0;
<span class="lineNum">     662 </span>            :         bulk = uvm_km_pages.hiwat;
<span class="lineNum">     663 </span>            :         while (len &lt; uvm_km_pages.hiwat &amp;&amp; bulk &gt; 0) {
<span class="lineNum">     664 </span>            :                 bulk = MIN(bulk, uvm_km_pages.hiwat - len);
<span class="lineNum">     665 </span>            :                 addr = vm_map_min(kernel_map);
<span class="lineNum">     666 </span>            :                 if (uvm_map(kernel_map, &amp;addr, (vsize_t)bulk &lt;&lt; PAGE_SHIFT,
<span class="lineNum">     667 </span>            :                     NULL, UVM_UNKNOWN_OFFSET, 0,
<span class="lineNum">     668 </span>            :                     UVM_MAPFLAG(PROT_READ | PROT_WRITE,
<span class="lineNum">     669 </span>            :                     PROT_READ | PROT_WRITE, MAP_INHERIT_NONE,
<span class="lineNum">     670 </span>            :                     MADV_RANDOM, UVM_KMF_TRYLOCK)) != 0) {
<span class="lineNum">     671 </span>            :                         bulk /= 2;
<span class="lineNum">     672 </span>            :                         continue;
<span class="lineNum">     673 </span>            :                 }
<span class="lineNum">     674 </span>            : 
<span class="lineNum">     675 </span>            :                 for (i = len; i &lt; len + bulk; i++, addr += PAGE_SIZE)
<span class="lineNum">     676 </span>            :                         uvm_km_pages.page[i] = addr;
<span class="lineNum">     677 </span>            :                 len += bulk;
<span class="lineNum">     678 </span>            :         }
<span class="lineNum">     679 </span>            : 
<span class="lineNum">     680 </span>            :         uvm_km_pages.free = len;
<span class="lineNum">     681 </span>            :         for (i = len; i &lt; UVM_KM_PAGES_HIWAT_MAX; i++)
<span class="lineNum">     682 </span>            :                 uvm_km_pages.page[i] = 0;
<span class="lineNum">     683 </span>            : 
<span class="lineNum">     684 </span>            :         /* tone down if really high */
<span class="lineNum">     685 </span>            :         if (uvm_km_pages.lowat &gt; 512)
<span class="lineNum">     686 </span>            :                 uvm_km_pages.lowat = 512;
<span class="lineNum">     687 </span>            : }
<span class="lineNum">     688 </span>            : 
<span class="lineNum">     689 </span>            : void
<span class="lineNum">     690 </span>            : uvm_km_page_lateinit(void)
<span class="lineNum">     691 </span>            : {
<span class="lineNum">     692 </span>            :         kthread_create_deferred(uvm_km_createthread, NULL);
<span class="lineNum">     693 </span>            : }
<span class="lineNum">     694 </span>            : 
<span class="lineNum">     695 </span>            : void
<span class="lineNum">     696 </span>            : uvm_km_createthread(void *arg)
<span class="lineNum">     697 </span>            : {
<span class="lineNum">     698 </span>            :         kthread_create(uvm_km_thread, NULL, &amp;uvm_km_pages.km_proc, &quot;kmthread&quot;);
<span class="lineNum">     699 </span>            : }
<span class="lineNum">     700 </span>            : 
<span class="lineNum">     701 </span>            : /*
<span class="lineNum">     702 </span>            :  * Endless loop.  We grab pages in increments of 16 pages, then
<span class="lineNum">     703 </span>            :  * quickly swap them into the list.  At some point we can consider
<span class="lineNum">     704 </span>            :  * returning memory to the system if we have too many free pages,
<span class="lineNum">     705 </span>            :  * but that's not implemented yet.
<span class="lineNum">     706 </span>            :  */
<span class="lineNum">     707 </span>            : void
<span class="lineNum">     708 </span>            : uvm_km_thread(void *arg)
<span class="lineNum">     709 </span>            : {
<span class="lineNum">     710 </span>            :         vaddr_t pg[16];
<span class="lineNum">     711 </span>            :         int i;
<span class="lineNum">     712 </span>            :         int allocmore = 0;
<span class="lineNum">     713 </span>            :         int flags;
<span class="lineNum">     714 </span>            :         struct uvm_km_free_page *fp = NULL;
<span class="lineNum">     715 </span>            : 
<span class="lineNum">     716 </span>            :         KERNEL_UNLOCK();
<span class="lineNum">     717 </span>            : 
<span class="lineNum">     718 </span>            :         for (;;) {
<span class="lineNum">     719 </span>            :                 mtx_enter(&amp;uvm_km_pages.mtx);
<span class="lineNum">     720 </span>            :                 if (uvm_km_pages.free &gt;= uvm_km_pages.lowat &amp;&amp;
<span class="lineNum">     721 </span>            :                     uvm_km_pages.freelist == NULL) {
<span class="lineNum">     722 </span>            :                         msleep(&amp;uvm_km_pages.km_proc, &amp;uvm_km_pages.mtx,
<span class="lineNum">     723 </span>            :                             PVM, &quot;kmalloc&quot;, 0);
<span class="lineNum">     724 </span>            :                 }
<span class="lineNum">     725 </span>            :                 allocmore = uvm_km_pages.free &lt; uvm_km_pages.lowat;
<span class="lineNum">     726 </span>            :                 fp = uvm_km_pages.freelist;
<span class="lineNum">     727 </span>            :                 uvm_km_pages.freelist = NULL;
<span class="lineNum">     728 </span>            :                 uvm_km_pages.freelistlen = 0;
<span class="lineNum">     729 </span>            :                 mtx_leave(&amp;uvm_km_pages.mtx);
<span class="lineNum">     730 </span>            : 
<span class="lineNum">     731 </span>            :                 if (allocmore) {
<span class="lineNum">     732 </span>            :                         /*
<span class="lineNum">     733 </span>            :                          * If there was nothing on the freelist, then we
<span class="lineNum">     734 </span>            :                          * must obtain at least one page to make progress.
<span class="lineNum">     735 </span>            :                          * So, only use UVM_KMF_TRYLOCK for the first page
<span class="lineNum">     736 </span>            :                          * if fp != NULL
<span class="lineNum">     737 </span>            :                          */
<span class="lineNum">     738 </span>            :                         flags = UVM_MAPFLAG(PROT_READ | PROT_WRITE,
<span class="lineNum">     739 </span>            :                             PROT_READ | PROT_WRITE, MAP_INHERIT_NONE,
<span class="lineNum">     740 </span>            :                             MADV_RANDOM, fp != NULL ? UVM_KMF_TRYLOCK : 0);
<span class="lineNum">     741 </span>            :                         memset(pg, 0, sizeof(pg));
<span class="lineNum">     742 </span>            :                         for (i = 0; i &lt; nitems(pg); i++) {
<span class="lineNum">     743 </span>            :                                 pg[i] = vm_map_min(kernel_map);
<span class="lineNum">     744 </span>            :                                 if (uvm_map(kernel_map, &amp;pg[i], PAGE_SIZE,
<span class="lineNum">     745 </span>            :                                     NULL, UVM_UNKNOWN_OFFSET, 0, flags) != 0) {
<span class="lineNum">     746 </span>            :                                         pg[i] = 0;
<span class="lineNum">     747 </span>            :                                         break;
<span class="lineNum">     748 </span>            :                                 }
<span class="lineNum">     749 </span>            : 
<span class="lineNum">     750 </span>            :                                 /* made progress, so don't sleep for more */
<span class="lineNum">     751 </span>            :                                 flags = UVM_MAPFLAG(PROT_READ | PROT_WRITE,
<span class="lineNum">     752 </span>            :                                     PROT_READ | PROT_WRITE, MAP_INHERIT_NONE,
<span class="lineNum">     753 </span>            :                                     MADV_RANDOM, UVM_KMF_TRYLOCK);
<span class="lineNum">     754 </span>            :                         }
<span class="lineNum">     755 </span>            : 
<span class="lineNum">     756 </span>            :                         mtx_enter(&amp;uvm_km_pages.mtx);
<span class="lineNum">     757 </span>            :                         for (i = 0; i &lt; nitems(pg); i++) {
<span class="lineNum">     758 </span>            :                                 if (uvm_km_pages.free ==
<span class="lineNum">     759 </span>            :                                     nitems(uvm_km_pages.page))
<span class="lineNum">     760 </span>            :                                         break;
<span class="lineNum">     761 </span>            :                                 else if (pg[i] != 0)
<span class="lineNum">     762 </span>            :                                         uvm_km_pages.page[uvm_km_pages.free++]
<span class="lineNum">     763 </span>            :                                             = pg[i];
<span class="lineNum">     764 </span>            :                         }
<span class="lineNum">     765 </span>            :                         wakeup(&amp;uvm_km_pages.free);
<span class="lineNum">     766 </span>            :                         mtx_leave(&amp;uvm_km_pages.mtx);
<span class="lineNum">     767 </span>            : 
<span class="lineNum">     768 </span>            :                         /* Cleanup left-over pages (if any). */
<span class="lineNum">     769 </span>            :                         for (; i &lt; nitems(pg); i++) {
<span class="lineNum">     770 </span>            :                                 if (pg[i] != 0) {
<span class="lineNum">     771 </span>            :                                         uvm_unmap(kernel_map,
<span class="lineNum">     772 </span>            :                                             pg[i], pg[i] + PAGE_SIZE);
<span class="lineNum">     773 </span>            :                                 }
<span class="lineNum">     774 </span>            :                         }
<span class="lineNum">     775 </span>            :                 }
<span class="lineNum">     776 </span>            :                 while (fp) {
<span class="lineNum">     777 </span>            :                         fp = uvm_km_doputpage(fp);
<span class="lineNum">     778 </span>            :                 }
<span class="lineNum">     779 </span>            :         }
<span class="lineNum">     780 </span>            : }
<span class="lineNum">     781 </span>            : 
<span class="lineNum">     782 </span>            : struct uvm_km_free_page *
<span class="lineNum">     783 </span>            : uvm_km_doputpage(struct uvm_km_free_page *fp)
<span class="lineNum">     784 </span>            : {
<span class="lineNum">     785 </span>            :         vaddr_t va = (vaddr_t)fp;
<span class="lineNum">     786 </span>            :         struct vm_page *pg;
<span class="lineNum">     787 </span>            :         int     freeva = 1;
<span class="lineNum">     788 </span>            :         struct uvm_km_free_page *nextfp = fp-&gt;next;
<span class="lineNum">     789 </span>            : 
<span class="lineNum">     790 </span>            :         pg = uvm_atopg(va);
<span class="lineNum">     791 </span>            : 
<span class="lineNum">     792 </span>            :         pmap_kremove(va, PAGE_SIZE);
<span class="lineNum">     793 </span>            :         pmap_update(kernel_map-&gt;pmap);
<span class="lineNum">     794 </span>            : 
<span class="lineNum">     795 </span>            :         mtx_enter(&amp;uvm_km_pages.mtx);
<span class="lineNum">     796 </span>            :         if (uvm_km_pages.free &lt; uvm_km_pages.hiwat) {
<span class="lineNum">     797 </span>            :                 uvm_km_pages.page[uvm_km_pages.free++] = va;
<span class="lineNum">     798 </span>            :                 freeva = 0;
<span class="lineNum">     799 </span>            :         }
<span class="lineNum">     800 </span>            :         mtx_leave(&amp;uvm_km_pages.mtx);
<span class="lineNum">     801 </span>            : 
<span class="lineNum">     802 </span>            :         if (freeva)
<span class="lineNum">     803 </span>            :                 uvm_unmap(kernel_map, va, va + PAGE_SIZE);
<span class="lineNum">     804 </span>            : 
<span class="lineNum">     805 </span>            :         uvm_pagefree(pg);
<span class="lineNum">     806 </span>            :         return (nextfp);
<span class="lineNum">     807 </span>            : }
<span class="lineNum">     808 </span>            : #endif  /* !__HAVE_PMAP_DIRECT */
<a name="809"><span class="lineNum">     809 </span>            : </a>
<span class="lineNum">     810 </span>            : void *
<span class="lineNum">     811 </span><span class="lineNoCov">          0 : km_alloc(size_t sz, const struct kmem_va_mode *kv,</span>
<span class="lineNum">     812 </span>            :     const struct kmem_pa_mode *kp, const struct kmem_dyn_mode *kd)
<span class="lineNum">     813 </span>            : {
<span class="lineNum">     814 </span>            :         struct vm_map *map;
<span class="lineNum">     815 </span>            :         struct vm_page *pg;
<span class="lineNum">     816 </span><span class="lineNoCov">          0 :         struct pglist pgl;</span>
<span class="lineNum">     817 </span>            :         int mapflags = 0;
<span class="lineNum">     818 </span>            :         vm_prot_t prot;
<span class="lineNum">     819 </span>            :         paddr_t pla_align;
<span class="lineNum">     820 </span>            :         int pla_flags;
<span class="lineNum">     821 </span>            :         int pla_maxseg;
<span class="lineNum">     822 </span><span class="lineNoCov">          0 :         vaddr_t va, sva;</span>
<span class="lineNum">     823 </span>            : 
<span class="lineNum">     824 </span><span class="lineNoCov">          0 :         KASSERT(sz == round_page(sz));</span>
<span class="lineNum">     825 </span>            : 
<span class="lineNum">     826 </span><span class="lineNoCov">          0 :         TAILQ_INIT(&amp;pgl);</span>
<span class="lineNum">     827 </span>            : 
<span class="lineNum">     828 </span><span class="lineNoCov">          0 :         if (kp-&gt;kp_nomem || kp-&gt;kp_pageable)</span>
<span class="lineNum">     829 </span>            :                 goto alloc_va;
<span class="lineNum">     830 </span>            : 
<span class="lineNum">     831 </span><span class="lineNoCov">          0 :         pla_flags = kd-&gt;kd_waitok ? UVM_PLA_WAITOK : UVM_PLA_NOWAIT;</span>
<span class="lineNum">     832 </span><span class="lineNoCov">          0 :         pla_flags |= UVM_PLA_TRYCONTIG;</span>
<span class="lineNum">     833 </span><span class="lineNoCov">          0 :         if (kp-&gt;kp_zero)</span>
<span class="lineNum">     834 </span><span class="lineNoCov">          0 :                 pla_flags |= UVM_PLA_ZERO;</span>
<span class="lineNum">     835 </span>            : 
<span class="lineNum">     836 </span><span class="lineNoCov">          0 :         pla_align = kp-&gt;kp_align;</span>
<span class="lineNum">     837 </span>            : #ifdef __HAVE_PMAP_DIRECT
<span class="lineNum">     838 </span><span class="lineNoCov">          0 :         if (pla_align &lt; kv-&gt;kv_align)</span>
<span class="lineNum">     839 </span><span class="lineNoCov">          0 :                 pla_align = kv-&gt;kv_align;</span>
<span class="lineNum">     840 </span>            : #endif
<span class="lineNum">     841 </span><span class="lineNoCov">          0 :         pla_maxseg = kp-&gt;kp_maxseg;</span>
<span class="lineNum">     842 </span><span class="lineNoCov">          0 :         if (pla_maxseg == 0)</span>
<span class="lineNum">     843 </span><span class="lineNoCov">          0 :                 pla_maxseg = sz / PAGE_SIZE;</span>
<span class="lineNum">     844 </span>            : 
<span class="lineNum">     845 </span><span class="lineNoCov">          0 :         if (uvm_pglistalloc(sz, kp-&gt;kp_constraint-&gt;ucr_low,</span>
<span class="lineNum">     846 </span><span class="lineNoCov">          0 :             kp-&gt;kp_constraint-&gt;ucr_high, pla_align, kp-&gt;kp_boundary,</span>
<span class="lineNum">     847 </span>            :             &amp;pgl, pla_maxseg, pla_flags)) { 
<span class="lineNum">     848 </span><span class="lineNoCov">          0 :                 return (NULL);</span>
<span class="lineNum">     849 </span>            :         }
<span class="lineNum">     850 </span>            : 
<span class="lineNum">     851 </span>            : #ifdef __HAVE_PMAP_DIRECT
<span class="lineNum">     852 </span>            :         /*
<span class="lineNum">     853 </span>            :          * Only use direct mappings for single page or single segment
<span class="lineNum">     854 </span>            :          * allocations.
<span class="lineNum">     855 </span>            :          */
<span class="lineNum">     856 </span><span class="lineNoCov">          0 :         if (kv-&gt;kv_singlepage || kp-&gt;kp_maxseg == 1) {</span>
<span class="lineNum">     857 </span><span class="lineNoCov">          0 :                 TAILQ_FOREACH(pg, &amp;pgl, pageq) {</span>
<span class="lineNum">     858 </span><span class="lineNoCov">          0 :                         va = pmap_map_direct(pg);</span>
<span class="lineNum">     859 </span><span class="lineNoCov">          0 :                         if (pg == TAILQ_FIRST(&amp;pgl))</span>
<span class="lineNum">     860 </span><span class="lineNoCov">          0 :                                 sva = va;</span>
<span class="lineNum">     861 </span>            :                 }
<span class="lineNum">     862 </span><span class="lineNoCov">          0 :                 return ((void *)sva);</span>
<span class="lineNum">     863 </span>            :         }
<span class="lineNum">     864 </span>            : #endif
<span class="lineNum">     865 </span>            : alloc_va:
<span class="lineNum">     866 </span>            :         prot = PROT_READ | PROT_WRITE;
<span class="lineNum">     867 </span>            : 
<span class="lineNum">     868 </span><span class="lineNoCov">          0 :         if (kp-&gt;kp_pageable) {</span>
<span class="lineNum">     869 </span><span class="lineNoCov">          0 :                 KASSERT(kp-&gt;kp_object);</span>
<span class="lineNum">     870 </span><span class="lineNoCov">          0 :                 KASSERT(!kv-&gt;kv_singlepage);</span>
<span class="lineNum">     871 </span>            :         } else {
<span class="lineNum">     872 </span><span class="lineNoCov">          0 :                 KASSERT(kp-&gt;kp_object == NULL);</span>
<span class="lineNum">     873 </span>            :         }
<span class="lineNum">     874 </span>            : 
<span class="lineNum">     875 </span><span class="lineNoCov">          0 :         if (kv-&gt;kv_singlepage) {</span>
<span class="lineNum">     876 </span><span class="lineNoCov">          0 :                 KASSERT(sz == PAGE_SIZE);</span>
<span class="lineNum">     877 </span>            : #ifdef __HAVE_PMAP_DIRECT
<span class="lineNum">     878 </span><span class="lineNoCov">          0 :                 panic(&quot;km_alloc: DIRECT single page&quot;);</span>
<span class="lineNum">     879 </span>            : #else
<span class="lineNum">     880 </span>            :                 mtx_enter(&amp;uvm_km_pages.mtx);
<span class="lineNum">     881 </span>            :                 while (uvm_km_pages.free == 0) {
<span class="lineNum">     882 </span>            :                         if (kd-&gt;kd_waitok == 0) {
<span class="lineNum">     883 </span>            :                                 mtx_leave(&amp;uvm_km_pages.mtx);
<span class="lineNum">     884 </span>            :                                 uvm_pglistfree(&amp;pgl);
<span class="lineNum">     885 </span>            :                                 return NULL;
<span class="lineNum">     886 </span>            :                         }
<span class="lineNum">     887 </span>            :                         msleep(&amp;uvm_km_pages.free, &amp;uvm_km_pages.mtx, PVM,
<span class="lineNum">     888 </span>            :                             &quot;getpage&quot;, 0);
<span class="lineNum">     889 </span>            :                 }
<span class="lineNum">     890 </span>            :                 va = uvm_km_pages.page[--uvm_km_pages.free];
<span class="lineNum">     891 </span>            :                 if (uvm_km_pages.free &lt; uvm_km_pages.lowat &amp;&amp;
<span class="lineNum">     892 </span>            :                     curproc != uvm_km_pages.km_proc) {
<span class="lineNum">     893 </span>            :                         if (kd-&gt;kd_slowdown)
<span class="lineNum">     894 </span>            :                                 *kd-&gt;kd_slowdown = 1;
<span class="lineNum">     895 </span>            :                         wakeup(&amp;uvm_km_pages.km_proc);
<span class="lineNum">     896 </span>            :                 }
<span class="lineNum">     897 </span>            :                 mtx_leave(&amp;uvm_km_pages.mtx);
<span class="lineNum">     898 </span>            : #endif
<span class="lineNum">     899 </span>            :         } else {
<span class="lineNum">     900 </span>            :                 struct uvm_object *uobj = NULL;
<span class="lineNum">     901 </span>            : 
<span class="lineNum">     902 </span><span class="lineNoCov">          0 :                 if (kd-&gt;kd_trylock)</span>
<span class="lineNum">     903 </span><span class="lineNoCov">          0 :                         mapflags |= UVM_KMF_TRYLOCK;</span>
<span class="lineNum">     904 </span>            : 
<span class="lineNum">     905 </span><span class="lineNoCov">          0 :                 if (kp-&gt;kp_object)</span>
<span class="lineNum">     906 </span><span class="lineNoCov">          0 :                         uobj = *kp-&gt;kp_object;</span>
<span class="lineNum">     907 </span>            : try_map:
<span class="lineNum">     908 </span><span class="lineNoCov">          0 :                 map = *kv-&gt;kv_map;</span>
<span class="lineNum">     909 </span><span class="lineNoCov">          0 :                 va = vm_map_min(map);</span>
<span class="lineNum">     910 </span><span class="lineNoCov">          0 :                 if (uvm_map(map, &amp;va, sz, uobj, kd-&gt;kd_prefer,</span>
<span class="lineNum">     911 </span><span class="lineNoCov">          0 :                     kv-&gt;kv_align, UVM_MAPFLAG(prot, prot, MAP_INHERIT_NONE,</span>
<span class="lineNum">     912 </span>            :                     MADV_RANDOM, mapflags))) {
<span class="lineNum">     913 </span><span class="lineNoCov">          0 :                         if (kv-&gt;kv_wait &amp;&amp; kd-&gt;kd_waitok) {</span>
<span class="lineNum">     914 </span><span class="lineNoCov">          0 :                                 tsleep(map, PVM, &quot;km_allocva&quot;, 0);</span>
<span class="lineNum">     915 </span><span class="lineNoCov">          0 :                                 goto try_map;</span>
<span class="lineNum">     916 </span>            :                         }
<span class="lineNum">     917 </span><span class="lineNoCov">          0 :                         uvm_pglistfree(&amp;pgl);</span>
<span class="lineNum">     918 </span><span class="lineNoCov">          0 :                         return (NULL);</span>
<span class="lineNum">     919 </span>            :                 }
<span class="lineNum">     920 </span><span class="lineNoCov">          0 :         }</span>
<span class="lineNum">     921 </span><span class="lineNoCov">          0 :         sva = va;</span>
<span class="lineNum">     922 </span><span class="lineNoCov">          0 :         TAILQ_FOREACH(pg, &amp;pgl, pageq) {</span>
<span class="lineNum">     923 </span><span class="lineNoCov">          0 :                 if (kp-&gt;kp_pageable)</span>
<span class="lineNum">     924 </span><span class="lineNoCov">          0 :                         pmap_enter(pmap_kernel(), va, VM_PAGE_TO_PHYS(pg),</span>
<span class="lineNum">     925 </span>            :                             prot, prot | PMAP_WIRED);
<span class="lineNum">     926 </span>            :                 else
<span class="lineNum">     927 </span><span class="lineNoCov">          0 :                         pmap_kenter_pa(va, VM_PAGE_TO_PHYS(pg), prot);</span>
<span class="lineNum">     928 </span><span class="lineNoCov">          0 :                 va += PAGE_SIZE;</span>
<span class="lineNum">     929 </span>            :         }
<span class="lineNum">     930 </span>            :         pmap_update(pmap_kernel());
<span class="lineNum">     931 </span><span class="lineNoCov">          0 :         return ((void *)sva);</span>
<span class="lineNum">     932 </span><span class="lineNoCov">          0 : }</span>
<a name="933"><span class="lineNum">     933 </span>            : </a>
<span class="lineNum">     934 </span>            : void
<span class="lineNum">     935 </span><span class="lineNoCov">          0 : km_free(void *v, size_t sz, const struct kmem_va_mode *kv,</span>
<span class="lineNum">     936 </span>            :     const struct kmem_pa_mode *kp)
<span class="lineNum">     937 </span>            : {
<span class="lineNum">     938 </span>            :         vaddr_t sva, eva, va;
<span class="lineNum">     939 </span>            :         struct vm_page *pg;
<span class="lineNum">     940 </span><span class="lineNoCov">          0 :         struct pglist pgl;</span>
<span class="lineNum">     941 </span>            : 
<span class="lineNum">     942 </span><span class="lineNoCov">          0 :         sva = (vaddr_t)v;</span>
<span class="lineNum">     943 </span><span class="lineNoCov">          0 :         eva = sva + sz;</span>
<span class="lineNum">     944 </span>            : 
<span class="lineNum">     945 </span><span class="lineNoCov">          0 :         if (kp-&gt;kp_nomem)</span>
<span class="lineNum">     946 </span>            :                 goto free_va;
<span class="lineNum">     947 </span>            : 
<span class="lineNum">     948 </span>            : #ifdef __HAVE_PMAP_DIRECT
<span class="lineNum">     949 </span><span class="lineNoCov">          0 :         if (kv-&gt;kv_singlepage || kp-&gt;kp_maxseg == 1) {</span>
<span class="lineNum">     950 </span><span class="lineNoCov">          0 :                 TAILQ_INIT(&amp;pgl);</span>
<span class="lineNum">     951 </span><span class="lineNoCov">          0 :                 for (va = sva; va &lt; eva; va += PAGE_SIZE) {</span>
<span class="lineNum">     952 </span><span class="lineNoCov">          0 :                         pg = pmap_unmap_direct(va);</span>
<span class="lineNum">     953 </span><span class="lineNoCov">          0 :                         TAILQ_INSERT_TAIL(&amp;pgl, pg, pageq);</span>
<span class="lineNum">     954 </span>            :                 }
<span class="lineNum">     955 </span><span class="lineNoCov">          0 :                 uvm_pglistfree(&amp;pgl);</span>
<span class="lineNum">     956 </span><span class="lineNoCov">          0 :                 return;</span>
<span class="lineNum">     957 </span>            :         }
<span class="lineNum">     958 </span>            : #else
<span class="lineNum">     959 </span>            :         if (kv-&gt;kv_singlepage) {
<span class="lineNum">     960 </span>            :                 struct uvm_km_free_page *fp = v;
<span class="lineNum">     961 </span>            : 
<span class="lineNum">     962 </span>            :                 mtx_enter(&amp;uvm_km_pages.mtx);
<span class="lineNum">     963 </span>            :                 fp-&gt;next = uvm_km_pages.freelist;
<span class="lineNum">     964 </span>            :                 uvm_km_pages.freelist = fp;
<span class="lineNum">     965 </span>            :                 if (uvm_km_pages.freelistlen++ &gt; 16)
<span class="lineNum">     966 </span>            :                         wakeup(&amp;uvm_km_pages.km_proc);
<span class="lineNum">     967 </span>            :                 mtx_leave(&amp;uvm_km_pages.mtx);
<span class="lineNum">     968 </span>            :                 return;
<span class="lineNum">     969 </span>            :         }
<span class="lineNum">     970 </span>            : #endif
<span class="lineNum">     971 </span>            : 
<span class="lineNum">     972 </span><span class="lineNoCov">          0 :         if (kp-&gt;kp_pageable) {</span>
<span class="lineNum">     973 </span><span class="lineNoCov">          0 :                 pmap_remove(pmap_kernel(), sva, eva);</span>
<span class="lineNum">     974 </span>            :                 pmap_update(pmap_kernel());
<span class="lineNum">     975 </span><span class="lineNoCov">          0 :         } else {</span>
<span class="lineNum">     976 </span><span class="lineNoCov">          0 :                 TAILQ_INIT(&amp;pgl);</span>
<span class="lineNum">     977 </span><span class="lineNoCov">          0 :                 for (va = sva; va &lt; eva; va += PAGE_SIZE) {</span>
<span class="lineNum">     978 </span><span class="lineNoCov">          0 :                         paddr_t pa;</span>
<span class="lineNum">     979 </span>            : 
<span class="lineNum">     980 </span><span class="lineNoCov">          0 :                         if (!pmap_extract(pmap_kernel(), va, &amp;pa))</span>
<span class="lineNum">     981 </span><span class="lineNoCov">          0 :                                 continue;</span>
<span class="lineNum">     982 </span>            : 
<span class="lineNum">     983 </span><span class="lineNoCov">          0 :                         pg = PHYS_TO_VM_PAGE(pa);</span>
<span class="lineNum">     984 </span><span class="lineNoCov">          0 :                         if (pg == NULL) {</span>
<span class="lineNum">     985 </span><span class="lineNoCov">          0 :                                 panic(&quot;km_free: unmanaged page 0x%lx\n&quot;, pa);</span>
<span class="lineNum">     986 </span>            :                         }
<span class="lineNum">     987 </span><span class="lineNoCov">          0 :                         TAILQ_INSERT_TAIL(&amp;pgl, pg, pageq);</span>
<span class="lineNum">     988 </span><span class="lineNoCov">          0 :                 }</span>
<span class="lineNum">     989 </span><span class="lineNoCov">          0 :                 pmap_kremove(sva, sz);</span>
<span class="lineNum">     990 </span>            :                 pmap_update(pmap_kernel());
<span class="lineNum">     991 </span><span class="lineNoCov">          0 :                 uvm_pglistfree(&amp;pgl);</span>
<span class="lineNum">     992 </span>            :         }
<span class="lineNum">     993 </span>            : free_va:
<span class="lineNum">     994 </span><span class="lineNoCov">          0 :         uvm_unmap(*kv-&gt;kv_map, sva, eva);</span>
<span class="lineNum">     995 </span><span class="lineNoCov">          0 :         if (kv-&gt;kv_wait)</span>
<span class="lineNum">     996 </span><span class="lineNoCov">          0 :                 wakeup(*kv-&gt;kv_map);</span>
<span class="lineNum">     997 </span><span class="lineNoCov">          0 : }</span>
<span class="lineNum">     998 </span>            : 
<span class="lineNum">     999 </span>            : const struct kmem_va_mode kv_any = {
<span class="lineNum">    1000 </span>            :         .kv_map = &amp;kernel_map,
<span class="lineNum">    1001 </span>            : };
<span class="lineNum">    1002 </span>            : 
<span class="lineNum">    1003 </span>            : const struct kmem_va_mode kv_intrsafe = {
<span class="lineNum">    1004 </span>            :         .kv_map = &amp;kmem_map,
<span class="lineNum">    1005 </span>            : };
<span class="lineNum">    1006 </span>            : 
<span class="lineNum">    1007 </span>            : const struct kmem_va_mode kv_page = {
<span class="lineNum">    1008 </span>            :         .kv_singlepage = 1
<span class="lineNum">    1009 </span>            : };
<span class="lineNum">    1010 </span>            : 
<span class="lineNum">    1011 </span>            : const struct kmem_pa_mode kp_dirty = {
<span class="lineNum">    1012 </span>            :         .kp_constraint = &amp;no_constraint
<span class="lineNum">    1013 </span>            : };
<span class="lineNum">    1014 </span>            : 
<span class="lineNum">    1015 </span>            : const struct kmem_pa_mode kp_dma = {
<span class="lineNum">    1016 </span>            :         .kp_constraint = &amp;dma_constraint
<span class="lineNum">    1017 </span>            : };
<span class="lineNum">    1018 </span>            : 
<span class="lineNum">    1019 </span>            : const struct kmem_pa_mode kp_dma_contig = {
<span class="lineNum">    1020 </span>            :         .kp_constraint = &amp;dma_constraint,
<span class="lineNum">    1021 </span>            :         .kp_maxseg = 1
<span class="lineNum">    1022 </span>            : };
<span class="lineNum">    1023 </span>            : 
<span class="lineNum">    1024 </span>            : const struct kmem_pa_mode kp_dma_zero = {
<span class="lineNum">    1025 </span>            :         .kp_constraint = &amp;dma_constraint,
<span class="lineNum">    1026 </span>            :         .kp_zero = 1
<span class="lineNum">    1027 </span>            : };
<span class="lineNum">    1028 </span>            : 
<span class="lineNum">    1029 </span>            : const struct kmem_pa_mode kp_zero = {
<span class="lineNum">    1030 </span>            :         .kp_constraint = &amp;no_constraint,
<span class="lineNum">    1031 </span>            :         .kp_zero = 1
<span class="lineNum">    1032 </span>            : };
<span class="lineNum">    1033 </span>            : 
<span class="lineNum">    1034 </span>            : const struct kmem_pa_mode kp_pageable = {
<span class="lineNum">    1035 </span>            :         .kp_object = &amp;uvm.kernel_object,
<span class="lineNum">    1036 </span>            :         .kp_pageable = 1
<span class="lineNum">    1037 </span>            : /* XXX - kp_nomem, maybe, but we'll need to fix km_free. */
<span class="lineNum">    1038 </span>            : };
<span class="lineNum">    1039 </span>            : 
<span class="lineNum">    1040 </span>            : const struct kmem_pa_mode kp_none = {
<span class="lineNum">    1041 </span>            :         .kp_nomem = 1
<span class="lineNum">    1042 </span>            : };
<span class="lineNum">    1043 </span>            : 
<span class="lineNum">    1044 </span>            : const struct kmem_dyn_mode kd_waitok = {
<span class="lineNum">    1045 </span>            :         .kd_waitok = 1,
<span class="lineNum">    1046 </span>            :         .kd_prefer = UVM_UNKNOWN_OFFSET
<span class="lineNum">    1047 </span>            : };
<span class="lineNum">    1048 </span>            : 
<span class="lineNum">    1049 </span>            : const struct kmem_dyn_mode kd_nowait = {
<span class="lineNum">    1050 </span>            :         .kd_prefer = UVM_UNKNOWN_OFFSET
<span class="lineNum">    1051 </span>            : };
<span class="lineNum">    1052 </span>            : 
<span class="lineNum">    1053 </span>            : const struct kmem_dyn_mode kd_trylock = {
<span class="lineNum">    1054 </span>            :         .kd_trylock = 1,
<span class="lineNum">    1055 </span>            :         .kd_prefer = UVM_UNKNOWN_OFFSET
<span class="lineNum">    1056 </span>            : };
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
